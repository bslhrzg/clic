# clic/__init__.py

"""
CLIC: Configuration interaction and Lanczos for Impurity Calculations
"""


# Expose the most important C++ classes to the top level of the package.
#    This allows users to write `clic.Wavefunction` instead of
#    `clic.clic_clib.Wavefunction`.
from .clic_clib import (
   
    SlaterDeterminant,
    Wavefunction,
    Spin,
    SpinOrbitalOrder,

    apply_creation,
    apply_annihilation,
    get_creation_operator,
    get_annihilation_operator,

    apply_one_body_operator,
    apply_two_body_operator,

    get_connections_one_body,
    get_connections_two_body,


    build_hamiltonian_openmp,
)


# Expose the most important Python functions to the top level.
from .hamiltonians import (
    get_impurity_integrals,
    create_hubbard_V,
)

from .basis_1p import (
    transform_integrals_interleaved_to_alphafirst,
    umo2so,
    double_h,
    basis_change_h0_U
)

from .bath_transform import *

from .basis_Np import (
    get_fci_basis,
    partition_by_Sz,
    subbasis_by_Sz,
    get_starting_basis
)

from .ops import (
    one_rdm, 
    get_ham,
    get_one_body_terms,
    get_two_body_terms
)
from .gfs import *

from .mf import mfscf
from .bath_transform import *

from .sci import selective_ci, hamiltonian_generator, cipsi_one_iter

from .symmetries import *

from . import hybfit# clic/api.py
import numpy as np
from . import bath_transform, clic_clib as cc # Import for Wavefunction, SlaterDeterminant
from . import hamiltonians, basis_1p, basis_Np, ops, sci, mf, gfs, plotting
from . import results
from .config_models import SolverParameters, GfConfig # Use Pydantic for validated settings
from typing import Literal, Union, List, Optional 

from scipy.linalg import eigh,block_diag
import copy
from . import symmetries, io_utils
from tqdm import tqdm    # For the progress bar
import h5py 

class Model:
    """Represents the physical system via its Hamiltonian integrals."""
    def __init__(self, h0: np.ndarray, U: np.ndarray, M_spatial: int, Nelec: int):
        self.h0 = np.ascontiguousarray(h0, dtype=np.complex128)

        print("diag h0 = ")
        for i in range(np.shape(h0)[0]):
            print(f"{i} : {np.real(h0[i,i]):.3e}")

        self.U = np.ascontiguousarray(U, dtype=np.complex128)
        self.M = M_spatial
        self.Nelec = Nelec
        # We can add u, mu etc. if basis_transforms needs them
        self.u = U[0, M_spatial, 0, M_spatial].real if U.ndim == 4 and U.shape[0] > M_spatial else 0.0

        self.is_impurity_model: bool = False
        self.imp_indices: list[int] = []
        self.Nelec_imp: int | None = None

class GroundStateSolver:
    """The main API endpoint for running a ground state calculation."""
    def __init__(self, model: Model, settings: dict | SolverParameters):
        self.model = model
        # If raw dict is passed, validate it with our Pydantic model
        if isinstance(settings, dict):
            self.settings = SolverParameters(**settings)
        else:
            self.settings = settings
        

        self.result: results.ThermalGroundState | None = None 
        self.transformation_matrix = None # Store the transform here

    def _prepare_basis(self):
        method = self.settings.basis_prep_method
        print(f"Preparing one-particle basis using method: '{method}'")
        if method == "none":
            return
        
        elif method == 'rhf':
            hmf, es, Vs, rho = mf.mfscf_(self.model.h0,self.model.U,self.model.Nelec)
            h0,U_mat = basis_1p.basis_change_h0_U(self.model.h0,self.model.U,Vs)
            self.model.h0 = h0
            self.model.U = U_mat
            self.transformation_matrix = Vs

        elif method in ["dbl_chain","bath_no"]:

            if len(self.model.imp_indices) == 1:

                # self.model.h0 is the full 2M x 2M matrix for both spins
                # We operate on one spin sector (M x M)
                h0_spin = np.real(self.model.h0[:self.model.M, :self.model.M])
                Nelec_half = self.model.Nelec // 2 

                if method == "dbl_chain":
                    h_final_matrix, C_spin = bath_transform.get_double_chain_transform(
                        h0_spin, self.model.u, Nelec_half
                    )
                else :
                    h_final_matrix, C_spin = bath_transform.get_natural_orbital_transform(
                        h0_spin, self.model.u, Nelec_half
                    )


                h_final_matrix[0, 0] = -self.model.u / 2
              
                C = block_diag(C_spin, C_spin)
                self.model.h0 = C.conj().T @ self.model.h0 @ C
                self.transformation_matrix = C 
               

            # --- MULTI-ORBITAL IMPURITY CASE ---
            else: 
                print(f"Applying multi-orbital transformation for {len(self.model.imp_indices)} impurity orbitals...")

                # Create a dummy block dictionary for the spin channels
                block_dict = {'full_spin_block': list(range(self.model.M))}
                
                # Define impurity indices (now expecting global SPATIAL indices)
                imp_indices_spatial = self.model.imp_indices 
                
                # Create the Ne_per_block dictionary
                Ne_per_block = {'full_spin_block': self.model.Nelec // 2}
                
                # Choose which transformation to run based on the method
                if method == "dbl_chain":
                    print("Multi-orbital double chain not yet implemented. Stopping.")
                    # Or call the previous `perform_multi_orbital_no_transform` here if you fix it
                    return # Stop for now
                
                elif method == "bath_no":
                    # Call the new, simpler function
                    h_final, C_total = bath_transform.get_multi_orbital_natural_orbital_transform(
                        self.model.h0, 
                        self.model.U, 
                        self.model.Nelec, 
                        imp_indices_spatial, # Pass the SPATIAL indices
                    )
                
                # Transform the U tensor using the final transformation matrix
                _ , U_final = basis_1p.basis_change_h0_U(self.model.h0, self.model.U, C_total)
                
                # Update the model
                self.model.h0 = h_final
                self.model.U = U_final
                self.transformation_matrix = C_total
                
        else:
            raise NotImplementedError(f"Basis prep method '{method}' not implemented.")


    def _run_sci(self, seed: list[cc.SlaterDeterminant], max_iter_override: int | None = None) -> results.NelecLowEnergySubspace:
        """A helper to run the SCI calculation with a given starting seed."""
        ci_settings = self.settings.ci_method
        max_iter = max_iter_override if max_iter_override is not None else ci_settings.max_iter
        num_roots = 1 if max_iter_override is not None else ci_settings.num_roots
        print(f"Running SCI with max_iter={max_iter}, num_roots={num_roots} and seed size {len(seed)}...")
        
        result_obj = sci.selective_ci(
            h0=self.model.h0, 
            U=self.model.U,
            C=self.transformation_matrix,
            M=self.model.M, 
            Nelec=self.model.Nelec,
            seed=seed,  # Use the provided seed
            generator=sci.hamiltonian_generator, 
            selector=sci.cipsi_one_iter,
            num_roots=num_roots,
            max_iter=max_iter, 
            conv_tol=ci_settings.conv_tol,
            prune_thr=ci_settings.prune_thr,
            Nmul=ci_settings.Nmul, 
            verbose=True
        )
        return result_obj

    def solve(self) -> results.ThermalGroundState:
        """Runs the full workflow, including the optional NO step."""

        # Create a deep copy of the original model BEFORE any transformations are applied
        original_model = copy.deepcopy(self.model)

        # Edge case, Nelec = 0 
        if self.model.Nelec == 0 :
            vacuum_det = cc.SlaterDeterminant(self.model.M, [], [])
            psis = [cc.Wavefunction(self.model.M, [vacuum_det], [0+0j])]
            self.result = results.NelecLowEnergySubspace(M=self.model.M,Nelec=0,
                energies=[0],
                wavefunctions=psis,
                basis=[vacuum_det],
                transformation_matrix=None
            )
            # Even for this simple case, we create the full ThermalGroundState object
            thermal_result = results.ThermalGroundState(
                results_by_nelec={0: self.result},
                base_model=original_model,
                temperature=self.settings.initial_temperature
            )
            self.result = thermal_result
            return self.result


        self._prepare_basis()

        ci_settings = self.settings.ci_method
        if ci_settings.type == "fci":
            # FCI logic doesn't use NOs, handle it separately and early.
            print("Running FCI calculation...")
            result_obj = sci.do_fci(
                h0=self.model.h0, U=self.model.U, M=self.model.M, Nelec=self.model.Nelec, num_roots=ci_settings.num_roots,Sz=0, verbose=True)

        elif ci_settings.type == "sci":
            # --- Determine the initial seed for the first (or only) SCI run ---
            if self.settings.basis_prep_method == 'rhf':
                initial_seed = basis_Np.get_rhf_determinant(self.model.Nelec, self.model.M)
            else:
                if self.model.is_impurity_model:
                    initial_seed = basis_Np.get_imp_starting_basis(
                        np.real(self.model.h0), self.model.Nelec, self.model.Nelec_imp, self.model.imp_indices)
                else: 
                    initial_seed = basis_Np.get_starting_basis(np.real(self.model.h0), self.model.Nelec)
            
            # --- "no0" Workflow ---
            if self.settings.use_no == 'no0':
                print("\n--- Starting 'no0' procedure: calculating Natural Orbitals ---")
                
                # 1. Run a preliminary SCI calculation
                pre_sci_result = self._run_sci(seed=initial_seed, max_iter_override=1)
                psi_approx = pre_sci_result.ground_state_wavefunction
                
                # 2. Compute 1-RDM and get correctly sorted NO transformation matrix
                print("Calculating 1-RDM from approximate wavefunction...")
                rdm1_spatial = self.get_one_rdm(wavefunction=psi_approx, spatial=True)
                occ_numbers, C_no_spin_unsorted = eigh(rdm1_spatial)
                sort_indices = np.argsort(occ_numbers)[::-1]
                C_no_spin = C_no_spin_unsorted[:, sort_indices]
                C_no = block_diag(C_no_spin, C_no_spin)
                
                # 3. Transform the Hamiltonian into the NO basis
                print("Transforming Hamiltonian to Natural Orbital basis...")
                h0_no, U_no = basis_1p.basis_change_h0_U(self.model.h0, self.model.U, C_no)
                self.model.h0 = h0_no
                self.model.U = U_no
                
                # 4. Compose the transformation matrices
                if self.transformation_matrix is not None:
                    self.transformation_matrix = self.transformation_matrix @ C_no
                else:
                    self.transformation_matrix = C_no
                
                print("--- 'no0' procedure finished. Starting final calculation. ---\n")
                
                # The seed for the final calculation is the basis from the pre-SCI run.
                # The determinants themselves don't change, they are just labels. We are now simply
                # re-interpreting them in the new NO basis where the Hamiltonian has changed.
                final_seed = pre_sci_result.basis

                # 6. Run the final SCI 
                result_obj = self._run_sci(seed=final_seed)

            else: # --- Standard SCI Workflow (use_no == 'none') ---
                result_obj = self._run_sci(seed=initial_seed)

        # Finalize and store results
        result_obj.transformation_matrix = self.transformation_matrix
        
        print(f"\nCalculation finished. Ground state energy = {result_obj.ground_state_energy:.12f}")

        # Instantiate the final results object with the computed subspace and original model
        final_thermal_state = results.ThermalGroundState(
            results_by_nelec={result_obj.Nelec: result_obj},
            base_model=original_model, # Pass the whole original model
            temperature=self.settings.initial_temperature
        )

        self.result = final_thermal_state
        return self.result


    def get_one_rdm(self, wavefunction: cc.Wavefunction | None = None, spatial: bool = False) -> np.ndarray:
        """Computes the 1-RDM. Can compute for a provided wavefunction."""
        if wavefunction is None:
            if not self.result:
                raise RuntimeError("Solver has not been run and no wavefunction was provided.")
            # We need the ground state wavefunction from the correct Nelec sector
            _, _, wavefunction = self.result.find_absolute_ground_state()

        rdm = ops.one_rdm(wavefunction, self.model.M)
        
        if spatial:
            return rdm[:self.model.M, :self.model.M]
        return rdm
    
    def compute_stats(self, wavefunction: cc.Wavefunction):
        if self.model.is_impurity_model:
            imp_indices_spinfull = self.model.imp_indices + [iimp + self.model.M for iimp in self.model.imp_indices]
            gamma = ops.one_rdm(wavefunction,self.model.M,block=imp_indices_spinfull)
            occs = np.diag(gamma)
            print("* Occupations -------------")
            print(f"total: {np.sum(np.real(occs)):.3e}")
            for (i,iimp) in enumerate(imp_indices_spinfull):
                print(f"{i:>6} : {np.real(occs[i]):.3e}")
        else:
            gamma = ops.one_rdm(wavefunction,self.model.M)
            occs = np.diag(gamma)
            print(f"Total occupation: {np.sum(occs)}")
            for i in range(len(occs)):
                print(f"occ[{i}] = {np.real(occs[i]):.3e}")


    def save_result(self, filename: str):
        """Saves the ThermalGroundState result to a single HDF5 file."""
        if not self.result:
            raise RuntimeError("Solver has not been run yet.")
        self.result.save(filename)
        
class FockSpaceSolver:
    """
    API endpoint for finding the low-energy subspace across a range of particle
    numbers (Nelec). It orchestrates multiple fixed-Nelec calculations and
    combines them into a ThermalGroundState object for thermodynamic analysis.
    """
    def __init__(self, model: Model, settings: dict | SolverParameters, nelec_range: Union[tuple[int, int], Literal["auto"]]):
        self.base_model = model
        
        if isinstance(settings, dict):
            self.settings = SolverParameters(**settings)
        else:
            self.settings = settings
            
        self.nelec_setting = nelec_range
        self.result: results.ThermalGroundState | None = None

    def _solve_single_nelec(self, nelec: int, cache: dict) -> results.ThermalGroundState:
        """
        Helper to run a calculation for a single Nelec, using a cache.
        Returns a ThermalGroundState object, which contains the NelecLowEnergySubspace.
        """
        if nelec in cache:
            return cache[nelec]

        print(f"\n--- Solving for Nelec = {nelec} ---")
        current_model = copy.deepcopy(self.base_model)
        current_model.Nelec = nelec
        
        solver = GroundStateSolver(current_model, self.settings)
        # solver.solve() returns a ThermalGroundState object
        nelec_result_thermal = solver.solve() 
        
        cache[nelec] = nelec_result_thermal
        return nelec_result_thermal

    def _find_optimal_nelec(self) -> dict[int, results.NelecLowEnergySubspace]:
        """
        Iteratively searches for the Nelec that minimizes the ground state energy.
        Returns a dictionary of NelecLowEnergySubspace results centered around the minimum.
        """
        if not self.base_model.is_impurity_model:
            raise ValueError("Automatic Nelec search is only supported for impurity models.")

        nelec_start = self.base_model.Nelec
        print(f"\n--- Starting Automatic Search for Optimal Nelec (start = {nelec_start}) ---")

        energies = {}
        results_cache = {} # Caches ThermalGroundState objects
        subspace_cache = {} # Caches NelecLowEnergySubspace objects

        # --- Initial Point ---
        print(f"Calculating for starting Nelec = {nelec_start}...")
        result_thermal = self._solve_single_nelec(nelec_start, results_cache)
        _, e0, _ = result_thermal.find_absolute_ground_state()
        energies[nelec_start] = e0
        subspace_cache[nelec_start] = result_thermal.results_by_nelec[nelec_start]
        
        # --- Search Upwards ---
        print("\n--- Searching for minimum in increasing Nelec direction ---")
        nelec_curr = nelec_start
        while True:
            nelec_next = nelec_curr + 1
            if nelec_next > 2 * self.base_model.M:
                print("Reached maximum possible electrons. Stopping upward search.")
                break

            e_curr = energies[nelec_curr]
            result_thermal_next = self._solve_single_nelec(nelec_next, results_cache)
            _, e_next, _ = result_thermal_next.find_absolute_ground_state()
            energies[nelec_next] = e_next
            subspace_cache[nelec_next] = result_thermal_next.results_by_nelec[nelec_next]
            
            print(f"E({nelec_curr}) = {e_curr:.6f}, E({nelec_next}) = {e_next:.6f}")
            if e_next >= e_curr:
                print("Energy is no longer decreasing. Stopping upward search.")
                break
            nelec_curr = nelec_next

        # --- Search Downwards ---
        print("\n--- Searching for minimum in decreasing Nelec direction ---")
        nelec_curr = nelec_start
        while True:
            nelec_next = nelec_curr - 1
            if nelec_next < 0:
                print("Reached zero electrons. Stopping downward search.")
                break

            e_curr = energies[nelec_curr]
            result_thermal_next = self._solve_single_nelec(nelec_next, results_cache)
            _, e_next, _ = result_thermal_next.find_absolute_ground_state()
            energies[nelec_next] = e_next
            subspace_cache[nelec_next] = result_thermal_next.results_by_nelec[nelec_next]
            
            print(f"E({nelec_curr}) = {e_curr:.6f}, E({nelec_next}) = {e_next:.6f}")
            if e_next >= e_curr:
                print("Energy is no longer decreasing. Stopping downward search.")
                break
            nelec_curr = nelec_next
            
        # --- Find minimum and collect results ---
        nelec_min = min(energies, key=energies.get)
        
        print(f"\n--- Minimum energy found at Nelec = {nelec_min} (E = {energies[nelec_min]:.8f}) ---")
        print("Collecting results for thermal state around the minimum.")

        final_subspaces = {}
        for nelec_final in [nelec_min - 1, nelec_min, nelec_min + 1]:
            if 0 <= nelec_final <= 2 * self.base_model.M:
                if nelec_final in subspace_cache:
                    final_subspaces[nelec_final] = subspace_cache[nelec_final]
                else:
                    # This case should be rare but is included for robustness
                    result_thermal = self._solve_single_nelec(nelec_final, results_cache)
                    final_subspaces[nelec_final] = result_thermal.results_by_nelec[nelec_final]
        
        return final_subspaces


    def solve(self, initial_temperature: float = 300.0) -> results.ThermalGroundState:
        """
        Runs the full workflow for each Nelec and returns a combined result.
        If nelec_setting is 'auto', it finds the optimal Nelec first.
        """
        all_subspaces = {}

        if self.nelec_setting == "auto":
            all_subspaces = self._find_optimal_nelec()
        else:
            # Original behavior for a fixed range
            nelec_range = range(self.nelec_setting[0], self.nelec_setting[1] + 1)
            print(f"\n--- Starting Fock Space Calculation for Nelec in {list(nelec_range)} ---")
            results_cache = {} # Caches ThermalGroundState objects
            for nelec in nelec_range:
                # _solve_single_nelec returns a full ThermalGroundState object
                result_thermal = self._solve_single_nelec(nelec, results_cache)
                # We only need the NelecLowEnergySubspace from it
                all_subspaces[nelec] = result_thermal.results_by_nelec[nelec]
        
        # Instantiate the final results object with all computed subspaces and the base model
        self.result = results.ThermalGroundState(
            results_by_nelec=all_subspaces,
            base_model=self.base_model, # Pass the entire base model
            temperature=initial_temperature
        )
        
        # Report the absolute ground state found
        gs_nelec, gs_energy, _ = self.result.find_absolute_ground_state()
        print("\n--- Fock Space Calculation Finished ---")
        print(f"Absolute ground state found at Nelec = {gs_nelec} with E = {gs_energy:.12f}")
        
        return self.result


    def save_result(self, filename: str):
        if not self.result:
            raise RuntimeError("Solver has not been run yet.")
        self.result.save(filename)


# ----------------------------------------------------------------------------------

class GreenFunctionCalculator:
    """
    Calculates the thermally-averaged Green's function from a saved ThermalGroundState.
    """
    def __init__(self, settings: dict | GfConfig):
        if isinstance(settings, dict):
            self.settings = GfConfig(**settings)
        else:
            self.settings = settings
        
        self.thermal_state: results.ThermalGroundState | None = None

    def load_thermal_state(self):
        """Loads the ThermalGroundState from HDF5 and prepares it for calculation."""
        filepath = self.settings.ground_state_file
        print(f"Loading thermal state from HDF5 file '{filepath}'...")
        try:
            self.thermal_state = results.ThermalGroundState.load(filepath)
        except (FileNotFoundError, KeyError) as e:
            raise RuntimeError(f"Failed to load ground state file: {e}")
        
        print(f"Thermal state loaded. Initial temperature: {self.thermal_state.temperature:.1f} K.")
        print(f"Prepared thermal state with {len(self.thermal_state._all_states)} states for GF calculation.")

    def run(self) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Runs the thermally-averaged Green's function calculation.
        """
        self.load_thermal_state()

        p_gf = self.settings.green_function
        p_lanczos = self.settings.lanczos
        ws = np.linspace(p_gf.omega_mesh[0], p_gf.omega_mesh[1], int(p_gf.omega_mesh[2]))

        if p_gf.block_indices == "impurity":
            if not self.thermal_state.is_impurity_model:
                raise ValueError("GF block set to 'impurity' but loaded state is not an impurity model.")
            target_indices = sorted(self.thermal_state.imp_indices + [i + self.thermal_state.M for i in self.thermal_state.imp_indices])
        else:
            target_indices = sorted(list(set(p_gf.block_indices)))

        print(f"\nTargeting Green's function block for indices: {target_indices}")
        
        num_target = len(target_indices)
        # We will calculate the diagonal elements for now, as in your previous code.
        # This can be extended to the full block later if needed.
        G_total_diag = np.zeros((len(ws), num_target), dtype=np.complex128)
        
        # Cache for transformed Hamiltonians to avoid redundant calculations
        hamiltonian_cache = {}
        base_h0 = self.thermal_state.base_h0
        base_U = self.thermal_state.base_U
        M = self.thermal_state.M

        # Main loop over all states in the thermal ensemble
        iterator = zip(self.thermal_state._all_states, self.thermal_state.boltzmann_weights)
        for (state_info, weight) in tqdm(iterator, total=len(self.thermal_state._all_states), desc="Processing thermal states"):
            e_n, nelec_n, psi_n = state_info

            # Get the correct transformed Hamiltonian for this state's Nelec sector
            if nelec_n not in hamiltonian_cache:
                subspace = self.thermal_state.results_by_nelec[nelec_n]
                C = subspace.transformation_matrix
                if C is None:
                    h0_n, U_n = base_h0, base_U
                else:
                    h0_n, U_n = basis_1p.basis_change_h0_U(base_h0, base_U, C)
                
                one_bh_n = ops.get_one_body_terms(h0_n, M)
                two_bh_n = ops.get_two_body_terms(U_n, M)
                hamiltonian_cache[nelec_n] = (h0_n, U_n, one_bh_n, two_bh_n)
            
            h0_n, U_n, one_bh_n, two_bh_n = hamiltonian_cache[nelec_n]
            
            # Calculate the GF contribution from this single state
            for i, orb_idx in enumerate(target_indices):
                g_ii_n = gfs.green_function_from_time_propagation(
                    orb_idx, orb_idx, M, psi_n, e_n, ws, p_gf.eta,
                    target_indices, p_lanczos.NappH, h0_n, U_n,
                    one_bh_n, two_bh_n, p_lanczos.coeff_thresh, p_lanczos.L
                )
                G_total_diag[:, i] += weight * g_ii_n

        print("\nThermally-averaged calculation finished.")
        A_w_total = -(1 / np.pi) * np.imag(G_total_diag)
        
        # Save and plot the final, thermally-averaged results
        #if self.settings.output.gf_diag_txt_file:
        dodump=True 
        if dodump:
            io_utils.dump(
                A_w_total,
                ws,
                'A_w_thermal',
            )

        doplot=True
        #if self.settings.output.plot_file:
        if doplot:
            plotting.plot_spectral_function(
                ws, A_w_total, list(range(num_target)),
                f"Thermally-Averaged Spectral Function (T={self.thermal_state.temperature}K)",
                self.settings.output.plot_file
            )
        
        return ws, G_total_diag, A_w_total
    
# basis_1p.py
import numpy as np
from . import clic_clib as cc
from . import ops
from scipy.linalg import eig

def transform_integrals_interleaved_to_alphafirst(h0_int, U_int, M):
    """
    Transforms integrals from spin-interleaved to AlphaFirst (spin-blocked) ordering

    Args:
        h0_int (np.ndarray): One-body integrals in interleaved basis.
        U_int (np.ndarray): Two-body integrals in interleaved basis.
        M (int): Number of spatial orbitals.

    Returns:
        tuple[np.ndarray, np.ndarray]: h0_af, U_af in AlphaFirst basis.
    """
    K = 2 * M
    
    # Create the mapping from the new "AlphaFirst" index to the old "interleaved" index.
    # This is the permutation vector.
    # af_map[i_alphafirst] = i_interleaved
    af_map = np.zeros(K, dtype=int)
    
    # First M indices in the new basis are the alpha spins.
    # Their corresponding indices in the old basis are 0, 2, 4, ...
    af_map[:M] = np.arange(0, K, 2)
    
    # Last M indices in the new basis are the beta spins.
    # Their corresponding indices in the old basis are 1, 3, 5, ...
    af_map[M:] = np.arange(1, K, 2)

    # Use np.ix_ to create indexers that permute the axes of the arrays.
    # This is equivalent to the loops but is executed in highly optimized C/Fortran code.
    # h0_af[i, j] = h0_int[af_map[i], af_map[j]]
    h0_af = h0_int[np.ix_(af_map, af_map)]

    # For the 4D tensor, we permute all four axes using the same map.
    # U_af[i,j,k,l] = U_int[af_map[i], af_map[j], af_map[k], af_map[l]]
    U_af = U_int[np.ix_(af_map, af_map, af_map, af_map)]
    
    h0_af = np.ascontiguousarray(h0_af, dtype=np.complex128)
    U_af = np.ascontiguousarray(U_af, dtype=np.complex128)
    
    return h0_af, U_af

def double_h(h_core, M):
    """Converts spatial one-electron integrals to spin-orbital form (AlphaFirst)."""
    K = 2 * M
    h0 = np.zeros((K, K))
    for p in range(M):
        for q in range(M):
            # Alpha-alpha block
            h0[p, q] = h_core[p, q]
            # Beta-beta block
            h0[p + M, q + M] = h_core[p, q]
    return h0

def umo2so(U_mo, M):
    """
    Converts spatial physicist's integrals <pq|V|rs> to spin-orbital
    physicist's integrals <ij|V|kl> in AlphaFirst ordering.
    """
    K = 2 * M
    U_so = np.zeros((K, K, K, K))
    # U_mo[p,q,r,s] = <pq|V|rs>
    for p in range(M):
        for q in range(M):
            for r in range(M):
                for s in range(M):
                    val = U_mo[p, q, r, s]
                    if abs(val) > 1e-12:
                        p_a, p_b = p, p + M
                        q_a, q_b = q, q + M
                        r_a, r_b = r, r + M
                        s_a, s_b = s, s + M
                        
                        # αααα
                        U_so[p_a, q_a, r_a, s_a] = val
                        # ββββ
                        U_so[p_b, q_b, r_b, s_b] = val
                        # αβαβ
                        U_so[p_a, q_b, r_a, s_b] = val
                        # βαβα
                        U_so[p_b, q_a, r_b, s_a] = val
    return U_so

def basis_change_h0_U(A, B, C):
    """
    Performs a basis change on a 2-electron operator (U) and a 1-electron operator (A).

    This version uses a single, optimized einsum call for the 4D tensor transformation.

    Args:
        A (np.ndarray): A 2D array (matrix).
        B (np.ndarray): A 4D array (tensor).
        C (np.ndarray): The 2D transformation matrix.

    Returns:
        tuple[np.ndarray, np.ndarray]: A tuple containing the transformed Anew and Unew.
    """
    # Same calculation for the 2D matrix A
    Anew = C.T.conj() @ A @ C
    Unew = np.einsum('ai,bj,abgd,gk,dl->ijkl', C.conj(), C.conj(), B, C, C, optimize=True)
    
    return Anew, Unew


def get_natural_orbitals(wf,M,block):
    """Compute the natural orbitals for a given block"""
    gamma = ops.one_rdm(wf,M,block=block)
    eno,nos = eig(gamma)
    return nos
# basis_Np.py
from . import clic_clib as cc
from itertools import combinations, product
import numpy as np
from . import mf 

def get_fci_basis(num_spatial, num_electrons):
    """
    Return the Full Configuration Interaction (fci) basis 
    for N_electrons among M spatial orbitals, as a list of 
    SlaterDeterminants objects 
    """
    num_spin_orbitals = 2 * num_spatial
    basis_dets = []
    for occupied_indices in combinations(range(num_spin_orbitals), num_electrons):
        occ_a = [i for i in occupied_indices if i < num_spatial]
        occ_b = [i - num_spatial for i in occupied_indices if i >= num_spatial]
        det = cc.SlaterDeterminant(num_spatial, occ_a, occ_b)
        basis_dets.append(det)
    return sorted(basis_dets)

from collections import defaultdict

def partition_by_Sz(basis):
    """
    Group a list of SlaterDeterminant objects into S_z sectors.

    Returns
    -------
    inds : list[list[int]]
        For each block (ordered by Sz), the sorted indices of determinants in `basis`.
    blocks : list[float]
        The corresponding S_z values (in the same order as `inds`).
    """
    sz_to_inds = defaultdict(list)

    for idx, det in enumerate(basis):
        nα = len(det.alpha_occupied_indices())
        nβ = len(det.beta_occupied_indices())
        Sz = 0.5 * (nα - nβ)
        sz_to_inds[Sz].append(idx)

    blocks = sorted(sz_to_inds.keys())
    inds = [sorted(sz_to_inds[Sz]) for Sz in blocks]
    return inds, blocks

def subbasis_by_Sz(basis, target_Sz):
    """
    Extract the sub-basis with a given S_z.

    Returns
    -------
    subbasis : list[SlaterDeterminant]
    indices  : list[int]
        Indices (wrt the original `basis`) of the determinants in the subbasis.
    """
    inds, blocks = partition_by_Sz(basis)
    table = dict(zip(blocks, inds))
    idxs = table.get(target_Sz, [])
    return [basis[i] for i in idxs], idxs


def _extract_spatial_energies(h0, order="AlphaFirst", tol=1e-12):
    """
    Return spatial orbital energies eps (length M) from either
    spatial h0 (M×M) or spin-orbital h0 (2M×2M).
    """
    h0 = np.asarray(h0)
    if h0.ndim != 2 or h0.shape[0] != h0.shape[1]:
        raise ValueError("h0 must be square")

    K = h0.shape[0]
    diag = np.real_if_close(np.diag(h0).astype(float))

    # Already spatial?
    if K % 2 != 0:
        return diag, K

    M = K // 2
    if order == "AlphaFirst":
        d_a = diag[:M]
        d_b = diag[M:]
    elif order == "Interleaved":
        d_a = diag[0::2]
        d_b = diag[1::2]
    else:
        raise ValueError("order must be 'AlphaFirst' or 'Interleaved'")

    if np.allclose(d_a, d_b, atol=tol, rtol=0):
        # Consistent spin-orbital HF: same energies for α and β
        return d_a, M
    else:
        # Just treat as spatial
        return diag, K


def get_starting_basis(h0, Nelec, order="AlphaFirst", tol=1e-12):
    """
    Build a starting CI basis by filling lowest spatial orbital energies for the
    GIVEN SUBSPACE h0. It creates SlaterDeterminant objects that are local to this subspace.
    """
    eps, M_subspace = _extract_spatial_energies(h0, order=order, tol=tol)
    # The M for the determinant is ALWAYS the subspace M. This function is self-contained.
    M_for_det = M_subspace

    if not (0 <= Nelec <= 2*M_subspace):
        raise ValueError(f"Nelec ({Nelec}) cannot be between 0 and {2*M_subspace} for a subspace of size {M_subspace}.")

    # sort orbitals by energy, stable to preserve degeneracies
    order_idx = np.argsort(eps, kind="mergesort")
    eps_sorted = eps[order_idx]

    # group into degeneracy blocks
    blocks = []
    if M_subspace > 0:
        s = 0
        for i in range(1, M_subspace):
            if abs(eps_sorted[i] - eps_sorted[s]) > tol:
                blocks.append(order_idx[s:i].tolist())
                s = i
        blocks.append(order_idx[s:M_subspace].tolist())

    # how many pairs (doubly occupied orbitals) and whether odd electron
    pairs = Nelec // 2
    has_single = (Nelec % 2 == 1)

    # collect fully filled blocks and detect boundary
    fixed_blocks, boundary_block = [], []
    pairs_left = pairs
    for blk in blocks:
        if pairs_left >= len(blk):
            fixed_blocks.append(blk)
            pairs_left -= len(blk)
        else:
            boundary_block = blk
            break

    # all fixed paired orbitals
    fixed_pairs = [i for blk in fixed_blocks for i in blk]

    # choose pairs out of the boundary block if needed
    pair_sets = []
    if M_subspace > 0 and pairs_left > 0 and not boundary_block:
        raise RuntimeError(f"Cannot place {pairs} pairs in {M_subspace} orbitals. Not enough low-energy states for Nelec={Nelec}.")
        
    if pairs_left == 0:
        pair_sets.append(tuple(sorted(fixed_pairs)))
    elif boundary_block:
        for subset in combinations(boundary_block, pairs_left):
            pair_sets.append(tuple(sorted(fixed_pairs + list(subset))))

    dets = []
    if not has_single:
        # even number: fill pairs only
        for P in pair_sets:
            occ_a = sorted(list(P))
            occ_b = sorted(list(P))
            dets.append(cc.SlaterDeterminant(M_for_det, occ_a, occ_b))
    else:
        # odd number: put unpaired electron in lowest-energy remaining orbitals
        for P in pair_sets:
            Pset = set(P)
            remaining = [i for i in order_idx if i not in Pset]
            if not remaining:
                continue
            # lowest energy among remaining
            e0 = eps[remaining[0]]
            singles_block = [i for i in remaining if abs(eps[i]-e0) <= tol]

            for s in singles_block:
                # unpaired alpha
                occ_a = sorted(list(Pset) + [s])
                occ_b = sorted(list(Pset))
                dets.append(cc.SlaterDeterminant(M_for_det, occ_a, occ_b))
                # unpaired beta (comment out if you only want Ms >= 0)
                occ_a2 = sorted(list(Pset))
                occ_b2 = sorted(list(Pset) + [s])
                dets.append(cc.SlaterDeterminant(M_for_det, occ_a2, occ_b2))

    return sorted(dets)


def get_imp_starting_basis(h0, Nelec, Nelec_imp, imp_indices, order="AlphaFirst", tol=0.01):
    """
    Generates starting determinants with a fixed number of electrons on the impurity.
    It partitions the system, solves for ground states in each subspace, and then
    combines them into valid determinants for the full system.
    """
    K = h0.shape[0]
    M_global = K // 2 # This is the total M for the full system

    if Nelec == 0:
        print("Generating basis for Nelec = 0 (vacuum state).")
        # The only determinant is the one with no occupied orbitals.
        vacuum_det = cc.SlaterDeterminant(M_global, [], [])
        return [vacuum_det]
    
    # --- 1. Partition the system ---
    imp_indices = sorted(list(set(imp_indices)))
    M_imp = len(imp_indices)
    
    all_spatial_indices = np.arange(M_global)
    bath_indices = np.setdiff1d(all_spatial_indices, imp_indices).tolist()
    M_bath = len(bath_indices)

    print(f"Partitioning system: {M_imp} impurity orbitals, {M_bath} bath orbitals.")

    imp_spin_indices = imp_indices + [i + M_global for i in imp_indices]
    bath_spin_indices = bath_indices + [i + M_global for i in bath_indices]

    h0_imp = h0[np.ix_(imp_spin_indices, imp_spin_indices)]
    h0_bath = h0[np.ix_(bath_spin_indices, bath_spin_indices)]

    Nelec_bath = Nelec - Nelec_imp
    if Nelec_bath < 0:
        raise ValueError(f"Nelec_imp ({Nelec_imp}) cannot be greater than Nelec ({Nelec}).")

    print(f"Generating basis for {Nelec_imp} electrons on impurity and {Nelec_bath} on bath.")

    # --- 2. Call worker function on subspaces ---
    # The worker will return LOCAL determinants (e.g., M=7 for imp, M=21 for bath)
    imp_dets_local = get_starting_basis(h0_imp, Nelec_imp, order=order, tol=tol)
    bath_dets_local = get_starting_basis(h0_bath, Nelec_bath, order=order, tol=tol)
    
    if not imp_dets_local or not bath_dets_local:
        print("Warning: One subspace yielded zero determinants. Returning empty list.")
        return []

    print(f"Found {len(imp_dets_local)} impurity configurations and {len(bath_dets_local)} bath configurations.")
    
    # --- 3. Combine local results into global determinants ---
    final_dets = []
    for imp_det, bath_det in product(imp_dets_local, bath_dets_local):
        
        # Use the accessor methods to get the LOCAL occupations (indices from 0 to M_subspace-1)
        imp_alpha_local = imp_det.alpha_occupied_indices()
        imp_beta_local = imp_det.beta_occupied_indices()
        bath_alpha_local = bath_det.alpha_occupied_indices()
        bath_beta_local = bath_det.beta_occupied_indices()

        # Map local indices back to GLOBAL spatial indices
        global_alpha_imp = [imp_indices[i] for i in imp_alpha_local]
        global_beta_imp = [imp_indices[i] for i in imp_beta_local]
        global_alpha_bath = [bath_indices[i] for i in bath_alpha_local]
        global_beta_bath = [bath_indices[i] for i in bath_beta_local]
        
        # Combine and sort for the final determinant
        final_alpha = sorted(global_alpha_imp + global_alpha_bath)
        final_beta = sorted(global_beta_imp + global_beta_bath)
        
        # Create the FINAL determinant in the GLOBAL context (using M_global)
        final_dets.append(cc.SlaterDeterminant(M_global, final_alpha, final_beta))

    # Remove duplicates if any were generated (e.g., from odd electron cases)
    # The hash and eq bindings on your C++ class make this possible.
    unique_dets = sorted(list(set(final_dets)))
    if Nelec % 2 == 0:
        target_Sz = 0 
        print(f"Retaining only Sz={target_Sz} in starting basis")
        unique_dets,_ = subbasis_by_Sz(unique_dets, target_Sz)

    #for det in unique_dets:
    #    print(f"det : {det}")
    
    print(f"Generated a total of {len(unique_dets)} unique starting determinants.")
    return unique_dets

def get_rhf_determinant(Nelec, M):
    """
    Returns the RHF/ROHF Slater determinant in a spin-blocked MO basis.
    """
    if Nelec % 2 == 0:
    
        n_occ = Nelec // 2
        occ_hf = list(range(n_occ))

        return [cc.SlaterDeterminant(M, occ_hf, occ_hf)]
    else :
        n_occ = Nelec // 2
        occ_m = list(range(n_occ))
        occ_p = list(range(n_occ+1))

        b1 = cc.SlaterDeterminant(M, occ_m, occ_p)
        b2 = cc.SlaterDeterminant(M, occ_p, occ_m)

        return [b1,b2]


def expand_basis(current_basis,one_body_terms,two_body_terms):
    """Given a basis, return the basis accessible through the hamiltonian 
    (i.e. the unique set of all slater determinant generated by application of the hamiltonian onto 
    each elements of the basis)
    """

    connected_by_H1 = cc.get_connections_one_body(current_basis, one_body_terms)
    connected_by_H2 = cc.get_connections_two_body(current_basis, two_body_terms)
    
    new_basis_set = set(current_basis) | set(connected_by_H1) | set(connected_by_H2)
    return sorted(list(new_basis_set))



# bath_transform.py

import numpy as np
from scipy.linalg import eigh, block_diag
from . import symmetries, mf
# --------------------------------------------------------------------------
# Double chain for a single impurity
# --------------------------------------------------------------------------

def lanczos_tridiagonalization(H, v0):
    """
    Performs the Lanczos algorithm to tridiagonalize a Hermitian matrix H.
    Returns the tridiagonal matrix T and the transformation matrix Q such that H Q = Q T.
    """
    N = H.shape[0]
    if N == 0:
        return np.array([[]]), np.array([[]])
        
    Q = np.zeros((N, N), dtype=float)
    norm_v0 = np.linalg.norm(v0)
    if norm_v0 < 1e-15:
        # If v0 is zero (e.g., empty subspace), return empty matrices
        return np.array([[]]), np.array([[]])
    v = v0 / norm_v0
    Q[:, 0] = v

    alphas = np.zeros(N)
    betas = np.zeros(N - 1)

    for j in range(N):
        w = H @ v
        alpha = np.dot(v.conj(), w)
        alphas[j] = alpha

        if j < N - 1:
            w = w - alpha * v
            if j > 0:
                w = w - betas[j-1] * Q[:, j-1]
            
            beta = np.linalg.norm(w)
            
            if beta < 1e-12: # Invariant subspace found
                N_effective = j + 1
                T = np.diag(alphas[:N_effective]) + np.diag(betas[:j], k=1) + np.diag(betas[:j], k=-1)
                return T, Q[:, :N_effective]
            
            betas[j] = beta
            v = w / beta
            Q[:, j + 1] = v
    
    T = np.diag(alphas) + np.diag(betas, k=1) + np.diag(betas, k=-1)
    return T, Q


def get_double_chain_transform(h_spin, u, Nelec):
    """
    Performs the 5-step Natural Orbital transformation, yielding a Hamiltonian
    with a double-chain structure and the corresponding unitary transformation matrix C.

    Args:
        h_spin (np.ndarray): The initial single-particle Hamiltonian (M x M).
        u (float): The on-site interaction strength.
        Nelec (int): The number of electrons in the spin sector (Nelec_total / 2).

    Returns:
        tuple[np.ndarray, np.ndarray]:
            - h_final_matrix (np.ndarray): The final Hamiltonian in the double-chain basis.
            - C_total (np.ndarray): The total unitary transformation matrix C.
    """
    M = h_spin.shape[0]

    # --- (i) Mean-Field ---
    h_mf = h_spin.copy()
    h_mf[0, 0] += u * 0.5

    # --- (ii) Natural Orbital Basis for the Bath ---
    e_mf, C_mf = eigh(h_mf)
    rho_mf = C_mf[:, :Nelec] @ C_mf[:, :Nelec].T
    rho_bath = rho_mf[1:, 1:]
    n_no, W = eigh(rho_bath)
    
    occupations_dist_from_integer = np.minimum(n_no, 1 - n_no)
    b_idx = np.argmax(occupations_dist_from_integer)
    
    other_indices = [i for i in range(M - 1) if i != b_idx]
    # Sorting ensures a deterministic basis ordering
    filled_indices = sorted([i for i in other_indices if n_no[i] > 0.5])
    empty_indices = sorted([i for i in other_indices if n_no[i] <= 0.5])
    
    ordered_bath_indices = [b_idx] + filled_indices + empty_indices
    W_ordered = W[:, ordered_bath_indices]
    C1 = block_diag(1, W_ordered)

    # --- (iii) Bonding/Anti-bonding Transformation ---
    rho_no_basis = C1.T @ rho_mf @ C1
    rho_ib = rho_no_basis[:2, :2]
    _, U_bond = eigh(rho_ib)
    C2 = np.identity(M)
    C2[:2, :2] = U_bond
    
    C_upto_decoupled = C1 @ C2

    # --- (iv) Lanczos Tridiagonalization (Chain Transformation) ---
    h_decoupled = C_upto_decoupled.T @ h_mf @ C_upto_decoupled

    num_filled = len(filled_indices)
    conduction_indices = [0] + list(range(2 + num_filled, M))
    valence_indices = [1] + list(range(2, 2 + num_filled))

    h_conduction = h_decoupled[np.ix_(conduction_indices, conduction_indices)]
    v0_c = np.zeros(h_conduction.shape[0]); v0_c[0] = 1.0
    T_c, Q_c = lanczos_tridiagonalization(h_conduction, v0_c)

    h_valence = h_decoupled[np.ix_(valence_indices, valence_indices)]
    v0_v = np.zeros(h_valence.shape[0]); v0_v[0] = 1.0
    T_v, Q_v = lanczos_tridiagonalization(h_valence, v0_v)
    
    C_lanczos = np.identity(M)
    if Q_c.shape[1] > 0:
      C_lanczos[np.ix_(conduction_indices, conduction_indices)] = Q_c
    if Q_v.shape[1] > 0:
      C_lanczos[np.ix_(valence_indices, valence_indices)] = Q_v
      
    # C_to_chains transforms from original basis to the basis of Lanczos vectors
    # (permuted).
    C_to_chains = C_upto_decoupled @ C_lanczos

    # --- (v) Construct Final Basis and Transformation Matrix C_total ---
    # The final basis is {|i>, |b>, |c1>, |c2>, ..., |v1>, |v2>, ...}
    # where |i> and |b> are the impurity and special NO in the C1 basis.
    # The other vectors are the Lanczos chain vectors (excluding chain heads).
    
    # Get the vector representations of the chain states in the original basis
    # These are the columns of the C_to_chains matrix
    len_c = Q_c.shape[1]
    len_v = Q_v.shape[1]
    
    # The vector for the head of the conduction chain, |c0> = |A>, in the original basis
    c0_vec = C_to_chains[:, conduction_indices[0]] if len_c > 0 else np.zeros(M)
    # The vector for the head of the valence chain, |v0> = |B>, in the original basis
    v0_vec = C_to_chains[:, valence_indices[0]] if len_v > 0 else np.zeros(M)

    C_total = np.zeros((M, M))
    
    # The first two columns of C_total are the impurity |i> and special NO |b>
    # We recover them by rotating |c0> and |v0> back with U_bond.T
    # |i> = U_bond[0,0]|c0> + U_bond[0,1]|v0>
    # |b> = U_bond[1,0]|c0> + U_bond[1,1]|v0>
    C_total[:, 0] = U_bond[0, 0] * c0_vec + U_bond[0, 1] * v0_vec
    C_total[:, 1] = U_bond[1, 0] * c0_vec + U_bond[1, 1] * v0_vec

    # The remaining columns are the rest of the Lanczos chain vectors
    c_chain_start_idx = 2
    if len_c > 1:
        c_rest_indices_in_decoupled_basis = [conduction_indices[i] for i in range(1, len_c)]
        C_total[:, c_chain_start_idx : c_chain_start_idx + len_c - 1] = C_to_chains[:, c_rest_indices_in_decoupled_basis]

    v_chain_start_idx = c_chain_start_idx + (len_c - 1 if len_c > 0 else 0)
    if len_v > 1:
        v_rest_indices_in_decoupled_basis = [valence_indices[i] for i in range(1, len_v)]
        C_total[:, v_chain_start_idx : v_chain_start_idx + len_v - 1] = C_to_chains[:, v_rest_indices_in_decoupled_basis]

    # --- Transform the Hamiltonian and correct for the mean-field shift ---
    h_mf_final_basis = C_total.T @ h_mf @ C_total
    
    mean_field_correction_term = np.zeros_like(h_spin)
    mean_field_correction_term[0, 0] = u * 0.5
    transformed_correction = C_total.T @ mean_field_correction_term @ C_total
    
    h_final_matrix = h_mf_final_basis - transformed_correction
    
    return h_final_matrix, C_total

# --------------------------------------------------------------------------
# Double chain for a multi-orbital case 
# --------------------------------------------------------------------------
from .mf import mfscf 


def perform_multi_orbital_no_transform(h0, U, block_dict, impurity_indices, Ne_per_block):
    """
    Performs the natural orbital to double-chain transformation for a multi-orbital
    problem that is already block-diagonalized by symmetry.

    Args:
        h0 (np.ndarray): Full one-particle Hamiltonian (e.g., 2M x 2M), assumed block-diagonal.
        U (np.ndarray): Full two-particle interaction tensor, assumed block-diagonal.
        block_dict (dict): Maps symmetry block name to list of indices for one spin channel.
                           Example: {"a2u": [0, 5, 8], "t1u": [1, 2, 6, 7]}
        impurity_indices (list): List of global indices for all impurity orbitals.
        Ne_per_block (dict): Maps block name to the number of electrons for that block
                             (for a single spin channel).

    Returns:
        tuple[np.ndarray, np.ndarray]:
            - h_final (np.ndarray): The final Hamiltonian in the double-chain basis.
            - C_total (np.ndarray): The total unitary transformation matrix.
    """
    M = h0.shape[0] // 2 # Size of one spin channel
    h_final = np.zeros_like(h0, dtype=np.complex128)
    C_total = np.identity(h0.shape[0], dtype=np.complex128)

    # Process spin-up and spin-down blocks separately but identically
    for spin_offset in [0, M]: # 0 for spin-up, M for spin-down
        
        for block_name, global_indices in block_dict.items():
            
            current_indices = [i + spin_offset for i in global_indices]
            if not current_indices: continue

            h0_block = h0[np.ix_(current_indices, current_indices)]
            U_block = U[np.ix_(current_indices, current_indices, current_indices, current_indices)]
            Ne_block = Ne_per_block[block_name]

            block_imp_indices_global = [i for i in current_indices if i in impurity_indices]
            imp_indices_local = [global_indices.index(i - spin_offset) for i in block_imp_indices_global]

            print(f"\n--- Processing block '{block_name}' (Spin {'down' if spin_offset else 'up'}) ---")
            
            h_final_b, C_b = _transform_one_block(h0_block, U_block, Ne_block, imp_indices_local)

            h_final[np.ix_(current_indices, current_indices)] = h_final_b
            C_total[np.ix_(current_indices, current_indices)] = C_b
            
    return h_final, C_total


def _transform_one_block(h0_block, U_block, Ne_block, imp_indices_local):
    """
    Worker function to perform the 5-step transformation on a single symmetry block.
    """
    N_block = h0_block.shape[0]
    N_imp = len(imp_indices_local)

    if N_block == 0:
        return np.array([[]]), np.array([[]])
    if N_imp == 0 or N_block <= N_imp: # No bath to transform
        return h0_block, np.identity(N_block)

    # --- Step i: Mean-Field SCF on the block ---
    h0_doubled = block_diag(h0_block, h0_block)
    U_doubled = np.zeros((2*N_block, 2*N_block, 2*N_block, 2*N_block), dtype=U_block.dtype)
    U_doubled[np.ix_(*[np.arange(N_block)]*4)] = U_block
    U_doubled[np.ix_(*[np.arange(N_block, 2*N_block)]*4)] = U_block

    hmf_up, _, _, rho_full = mfscf(h0_doubled, U_doubled, 2 * Ne_block, maxiter=50)
    rho_up = rho_full[:N_block, :N_block]
    
    # --- Step ii: Natural Orbitals ---
    bath_indices_local = [i for i in range(N_block) if i not in imp_indices_local]
    rho_bath = rho_up[np.ix_(bath_indices_local, bath_indices_local)]
    n_no, W = eigh(rho_bath)
    
    occupations_dist = np.minimum(n_no, 1.0 - n_no)
    special_b_indices_in_bath = np.argsort(occupations_dist)[::-1][:N_imp]
    
    other_indices = np.setdiff1d(np.arange(len(bath_indices_local)), special_b_indices_in_bath)
    filled_indices = sorted([i for i in other_indices if n_no[i] > 0.5])
    empty_indices = sorted([i for i in other_indices if n_no[i] <= 0.5])

    ordered_bath_indices = list(special_b_indices_in_bath) + filled_indices + empty_indices
    W_ordered = W[:, ordered_bath_indices]

    C1 = np.identity(N_block, dtype=h0_block.dtype)
    C1[np.ix_(bath_indices_local, bath_indices_local)] = W_ordered
    
    # --- Step iii: Generalized Bonding/Anti-bonding ---
    rho_no_basis = C1.conj().T @ rho_up @ C1
    ib_subspace_indices = list(imp_indices_local) + list(range(N_imp, 2 * N_imp))
    rho_ib = rho_no_basis[np.ix_(ib_subspace_indices, ib_subspace_indices)]
    
    # Sort by occupation to identify bonding/anti-bonding
    n_ab, U_bond_unordered = eigh(rho_ib)
    ab_order = np.argsort(n_ab)
    U_bond = U_bond_unordered[:, ab_order] # Columns are anti-bonding then bonding
    
    C2 = np.identity(N_block, dtype=h0_block.dtype)
    C2[np.ix_(ib_subspace_indices, ib_subspace_indices)] = U_bond
    
    C_upto_decoupled = C1 @ C2

    # --- Step iv: Lanczos Chains for each channel ---
    h_decoupled = C_upto_decoupled.conj().T @ hmf_up @ C_upto_decoupled

    # We will create N_imp pairs of chains
    Q_c_list, Q_v_list = [], []
    conduction_spaces, valence_spaces = [], []

    num_empty_per_chain = len(empty_indices) // N_imp
    num_filled_per_chain = len(filled_indices) // N_imp

    C_lanczos = np.identity(N_block, dtype=h0_block.dtype)

    for k in range(N_imp):
        # Conduction chain for channel k
        anti_bond_idx = k
        empty_start = 2 * N_imp + len(filled_indices) + k * num_empty_per_chain
        empty_end = empty_start + num_empty_per_chain
        # Add remainder to last chain
        if k == N_imp - 1: empty_end = 2 * N_imp + len(filled_indices) + len(empty_indices)
        
        c_indices = [anti_bond_idx] + list(range(empty_start, empty_end))
        conduction_spaces.append(c_indices)
        
        h_c = h_decoupled[np.ix_(c_indices, c_indices)]
        v0_c = np.zeros(h_c.shape[0]); v0_c[0] = 1.0
        _, Q_c = lanczos_tridiagonalization(np.real(h_c), v0_c)
        Q_c_list.append(Q_c)
        if Q_c.shape[1] > 0:
            C_lanczos[np.ix_(c_indices, c_indices)] = Q_c

        # Valence chain for channel k
        bond_idx = N_imp + k
        filled_start = 2 * N_imp + k * num_filled_per_chain
        filled_end = filled_start + num_filled_per_chain
        if k == N_imp - 1: filled_end = 2 * N_imp + len(filled_indices)
        
        v_indices = [bond_idx] + list(range(filled_start, filled_end))
        valence_spaces.append(v_indices)

        h_v = h_decoupled[np.ix_(v_indices, v_indices)]
        v0_v = np.zeros(h_v.shape[0]); v0_v[0] = 1.0
        _, Q_v = lanczos_tridiagonalization(np.real(h_v), v0_v)
        Q_v_list.append(Q_v)
        if Q_v.shape[1] > 0:
            C_lanczos[np.ix_(v_indices, v_indices)] = Q_v

    C_to_chains = C_upto_decoupled @ C_lanczos

    # --- Step v: Final Assembly ---
    C_block_final = np.zeros((N_block, N_block), dtype=h0_block.dtype)
    
    # Recover original impurity and b orbitals by inverting the bonding transform
    # The heads of the chains are the A and B orbitals.
    c0_vectors = C_to_chains[:, [space[0] for space in conduction_spaces]] # Columns are |A_k>
    v0_vectors = C_to_chains[:, [space[0] for space in valence_spaces]]   # Columns are |B_k>
    
    # This matrix holds |A_1>...|A_N>, |B_1>...|B_N> as columns
    AB_vectors = np.hstack([c0_vectors, v0_vectors])
    # Rotate back to get |i_1>...|i_N>, |b_1>...|b_N>
    ib_vectors = AB_vectors @ U_bond.conj().T
    
    final_idx = 0
    # Impurity orbitals
    C_block_final[:, final_idx : final_idx + N_imp] = ib_vectors[:, :N_imp]
    final_idx += N_imp
    # Special b orbitals
    C_block_final[:, final_idx : final_idx + N_imp] = ib_vectors[:, N_imp:]
    final_idx += N_imp
    
    # Add the rest of the chain vectors
    for k in range(N_imp):
        space_indices = conduction_spaces[k]
        Q_c = Q_c_list[k]
        if Q_c.shape[1] > 1:
            num_chain_sites = Q_c.shape[1] - 1
            original_basis_indices = [space_indices[i] for i in range(1, Q_c.shape[1])]
            C_block_final[:, final_idx : final_idx + num_chain_sites] = C_to_chains[:, original_basis_indices]
            final_idx += num_chain_sites

    for k in range(N_imp):
        space_indices = valence_spaces[k]
        Q_v = Q_v_list[k]
        if Q_v.shape[1] > 1:
            num_chain_sites = Q_v.shape[1] - 1
            original_basis_indices = [space_indices[i] for i in range(1, Q_v.shape[1])]
            C_block_final[:, final_idx : final_idx + num_chain_sites] = C_to_chains[:, original_basis_indices]
            final_idx += num_chain_sites

    # Transform hmf and correct for the mean-field potential to get the transformed h0
    Vmf_up = hmf_up - h0_block
    h_final_block = (C_block_final.conj().T @ hmf_up @ C_block_final) - \
                    (C_block_final.conj().T @ Vmf_up @ C_block_final)

    return h_final_block, C_block_final

# --------------------------------------------------------------------------
# Natural orbitals 
# --------------------------------------------------------------------------

def get_natural_orbital_transform(h_spin, u, Nelec):
    """
    Performs a simple Natural Orbital transformation
    This corresponds to steps (i) and (ii) of the more complex procedure.
    """
    M = h_spin.shape[0]

    # Step 1: Mean-field Hamiltonian and its density matrix
    h_mf = h_spin.copy()
    h_mf[0, 0] += u * 0.5
    
    e_mf, C_mf = eigh(h_mf)
    rho_mf = C_mf[:, :Nelec] @ C_mf[:, :Nelec].T

    # Step 2: Diagonalize the bath part of the density matrix
    rho_bath = rho_mf[1:, 1:]
    # W contains the eigenvectors of rho_bath, which define the new bath basis
    _, W = eigh(rho_bath)
    
    # The transformation matrix C_no leaves the impurity alone and transforms the bath
    C_no = block_diag(1, W)
    
    # Apply the transformation to the original non-interacting Hamiltonian
    h_new_basis = C_no.T @ h_spin @ C_no
    
    return h_new_basis, C_no

# --------------------------------------------------------------------------

# --------------------------------------------------------------------------
# Natural Orbitals for a multi-orbital case
# --------------------------------------------------------------------------

def get_multi_orbital_natural_orbital_transform(
    h0: np.ndarray, 
    U: np.ndarray, 
    Nelec: int,
    impurity_indices: list[int]
) -> tuple[np.ndarray, np.ndarray]:
    """
    Performs a symmetry-preserving natural orbital transformation for a
    multi-orbital impurity problem.

    The transformation finds the natural orbitals for the bath *within each
    symmetry block* of the Hamiltonian, leaving the impurity orbitals untouched.
    This is the multi-orbital generalization of `get_natural_orbital_transform`.

    Args:
        h0 (np.ndarray): Full one-particle Hamiltonian (2M x 2M, AlphaFirst).
        U (np.ndarray): Full two-particle interaction tensor (2M x 2M x 2M x 2M).
        Nelec (int): The total number of electrons in the system.
        impurity_indices (list[int]): List of SPATIAL indices for all impurity
                                      orbitals (e.g., [0, 1] for a 2-orbital impurity).

    Returns:
        tuple[np.ndarray, np.ndarray]:
            - h_final (np.ndarray): The final Hamiltonian in the natural orbital basis.
            - C_total (np.ndarray): The total unitary transformation matrix (2M x 2M).
    """
    M = h0.shape[0] // 2
    h0_spin = h0[:M, :M]
    impurity_indices = sorted(list(set(impurity_indices)))
    
    print("--- Starting Symmetry-Aware Natural Orbital Transformation ---")
    
    # 1. Run SCF to get the converged density matrix
    print("Step 1: Running mean-field SCF to get the density matrix...")
    _, _, _, rho = mf.mfscf(h0, U, Nelec, maxiter=50)
    rho_spin = rho[:M, :M] # Work with the spatial (spin-up) block
    
    # 2. Analyze the symmetry of the original h0
    print("Step 2: Analyzing symmetries of the initial Hamiltonian...")
    sym_dict = symmetries.analyze_symmetries(h0_spin)
    blocks = sym_dict['blocks']
    print(f"Found {len(blocks)} symmetry blocks.")

    # 3. Build the transformation matrix C block-by-block
    print("Step 3: Calculating natural orbitals for each symmetry block...")
    C_spin = np.identity(M, dtype=h0.dtype)
    
    for i, block_indices in enumerate(blocks):
        # Partition the orbitals within this block into impurity and bath
        imp_in_block = [idx for idx in block_indices if idx in impurity_indices]
        bath_in_block = [idx for idx in block_indices if idx not in impurity_indices]
        
        print(f"  - Processing Block {i} (size {len(block_indices)}): "
              f"{len(imp_in_block)} impurity, {len(bath_in_block)} bath orbitals.")

        if not bath_in_block:
            # If no bath orbitals in this block, no transformation is needed.
            continue
            
        # Extract the bath-bath submatrix of the density matrix for this block
        rho_bath_block = rho_spin[np.ix_(bath_in_block, bath_in_block)]
        
        # Diagonalize it to get the eigenvectors 'W', which define the new bath basis
        _, W_block = eigh(rho_bath_block)
        
        # Place the transformation 'W_block' into the correct slice of C_spin.
        # This transforms the bath orbitals of this block, leaving others untouched.
        C_spin[np.ix_(bath_in_block, bath_in_block)] = W_block
        
    # 4. Assemble the full 2M x 2M transformation matrix and apply it
    print("Step 4: Assembling final transformation matrix and transforming h0...")
    C_total = block_diag(C_spin, C_spin)
    h_final = C_total.conj().T @ h0 @ C_total
    
    print("--- Transformation complete. ---")
    
    return h_final, C_total# config_models.py
from typing import Literal, Union, List, Optional 
from pydantic import BaseModel, Field, root_validator, ConfigDict


class BathConfig(BaseModel):
    nb: int = Field(..., gt=0)
    min_e: float
    max_e: float
    hybridization_V: float

class AimParameters(BaseModel):
    type: Literal['anderson_impurity_model']
    M_spatial: int
    M_imp: int
    Nelec_imp: int
    Nelec: Optional[int] = None
    interaction_u: float
    mu: Union[float, Literal["u/2"]]
    bath: BathConfig

    @root_validator(pre=False, skip_on_failure=True)
    def check_sizes(cls, values):
        m_imp, m_spatial = values.get('M_imp'), values.get('M_spatial')
        if m_imp is not None and m_spatial is not None and m_imp > m_spatial:
            raise ValueError("M_imp (impurity orbitals) cannot be larger than M_spatial (total orbitals).")
        return values

class FileDataSource(BaseModel):
    type: Literal["from_file"]
    filepath: str
    Nelec: int = Field(..., ge=0)
    spin_structure: Literal["alpha_first", "interleaved"] = "interleaved"

class FileImpurityModelParameters(BaseModel):
    """Defines an impurity model where integrals are loaded from a file."""
    type: Literal["impurity_from_file"]
    filepath: str
    M_imp: int                 # Number of impurity spatial orbitals
    Nelec_imp: int             # Target number of electrons ON THE IMPURITY
    Nelec: Optional[int] = None # Optional: TOTAL number of electrons
    spin_structure: Literal["alpha_first", "interleaved"] = "interleaved"


class ModelConfig(BaseModel):
    model_name: str
    parameters: Union[
        AimParameters, 
        FileDataSource, 
        FileImpurityModelParameters] = Field(..., discriminator='type')

class CiMethodConfig(BaseModel):
    type: Literal["sci", "fci"] = "sci"
    generator: Literal["hamiltonian_generator"]
    selector: Literal["cipsi"]
    num_roots: int = Field(1, gt=0) 
    max_iter: int = Field(2, gt=-1)
    conv_tol: float = Field(1e-6, gt=0)
    prune_thr: float = Field(1e-7, ge=0)
    Nmul: Union[float, None] = None

class SolverParameters(BaseModel):
    basis_prep_method: Literal["none", "rhf", "rhf_no", "bath_no","dbl_chain"]
    use_no: Literal["none","no0","no"] = "none"
    ci_method: CiMethodConfig
    nelec_range: Union[tuple[int, int], Literal["auto"], None] = None
    initial_temperature: float = 10.0 

class OutputConfig(BaseModel):
    ground_state_file: str = "clic_solve_results.h5"

class SolverConfig(BaseModel):
    model_file: str
    solver: SolverParameters
    output: OutputConfig

# --- Green's Function Configuration ---

class GreenFunctionParameters(BaseModel):
    omega_mesh: List[Union[int, float]]
    eta: float = Field(..., gt=0)
    block_indices: Union[Literal["impurity"], List[int]]

class LanczosParameters(BaseModel):
    L: int = Field(..., gt=0)
    NappH: int = Field(..., ge=0)
    coeff_thresh: float = Field(..., ge=0)

class GfOutputConfig(BaseModel):
    gf_data_file: str
    plot_file: str | None = None

class GfConfig(BaseModel):
    ground_state_file: str
    green_function: GreenFunctionParameters
    lanczos: LanczosParameters
    output: GfOutputConfig# block_hybridization_fitter.py (v3.1)

import numpy as np
import numpy.linalg as npl
import matplotlib.pyplot as plt

np.set_printoptions(precision=6, suppress=True)


class HybridizationFitter:
    """
    Fit a pole representation to a matrix valued hybridization Δ(ω).

    Input
      omega_grid: shape (N,)
      delta_complex: shape (N,) or (N, M, M)
      n_lanczos_blocks: number of Lanczos blocks to construct
      n_target_poles: number of poles after merging

    Pipeline
      1) Build a discrete measure μ_k = [−Im Δ(ω_k)/π] * w_k with trapezoid weights w_k
      2) Block Lanczos on the grid using μ_k to get a block Jacobi matrix T and M0
      3) Extract poles ε_j and PSD Hermitian residues R_j from T
      4) Merge adjacent poles using a warped metric controlled by kind and w0
      5) Reconstruct Δ on the grid and report errors
    """

    def __init__(self, omega_grid, delta_complex, n_lanczos_blocks, n_target_poles):
        self.omega = np.asarray(omega_grid, dtype=float)

        delta_in = np.asarray(delta_complex, dtype=np.complex128)
        if delta_in.ndim == 1:
            # promote to (N,1,1)
            self.delta_input = delta_in[:, np.newaxis, np.newaxis]
        elif delta_in.ndim == 3:
            self.delta_input = delta_in
        else:
            raise ValueError("delta_complex must be 1D or 3D")

        self.n_omega, self.m_orb, _ = self.delta_input.shape
        if self.omega.shape[0] != self.n_omega:
            raise ValueError("omega_grid and delta_complex length mismatch")

        self.block_size = self.m_orb
        self.n_lanczos_blocks = int(n_lanczos_blocks)
        self.n_target_poles = int(n_target_poles)

        # results
        self.T_lanczos = None
        self.M0_sqrt_lanczos = None
        self.delta_lanczos = None
        self.eps_lanczos = None
        self.R_lanczos = None
        self.eps_merged = None
        self.R_merged = None
        self.delta_merged = None

        print("HybridizationFitter initialized")
        print(f"  M = {self.m_orb}")
        print(f"  Lanczos blocks = {self.n_lanczos_blocks}")
        print(f"  Target poles = {self.n_target_poles}")

    # ------------- public API -------------

    def run_fit(self, warp_kind="atan", warp_w0=0.1, eta_broadening=0.005):
        print("\n--- Fitting and merging ---")
        self._fit_block_lanczos()
        self._extract_poles_from_T()

        z = self.omega + 1j * eta_broadening
        self.delta_lanczos = self._delta_from_poles(z, self.eps_lanczos, self.R_lanczos)

        self._merge_poles_block(kind=warp_kind, w0=warp_w0)

        self.delta_merged = self._delta_from_poles(z, self.eps_merged, self.R_merged)

        print("--- Done ---")
        print("\nFinal merged poles")
        for i in range(len(self.eps_merged)):
            c = np.sqrt(max(np.real(np.trace(self.R_merged[i])), 0.0))
            print(f"  pole {i}: e = {self.eps_merged[i]:+.6f}, sqrt Tr(R) = {c:.6f}")
        return self

    def analyze(self, eta_broadening=0.005):
        if self.delta_merged is None:
            raise RuntimeError("run_fit must be called first")

        print("\n--- Analysis ---")
        eL_im = self._rel_l2_mat(np.imag(self.delta_input), np.imag(self.delta_lanczos))
        eL_re = self._rel_l2_mat(np.real(self.delta_input), np.real(self.delta_lanczos))
        print(f"Lanczos ({len(self.eps_lanczos)} poles): Im = {eL_im:.3e}, Re = {eL_re:.3e}")

        eM_im = self._rel_l2_mat(np.imag(self.delta_input), np.imag(self.delta_merged))
        eM_re = self._rel_l2_mat(np.real(self.delta_input), np.real(self.delta_merged))
        print(f"Merged  ({self.n_target_poles} poles): Im = {eM_im:.3e}, Re = {eM_re:.3e}")

        chi = self._cost_function_mat(self.eps_merged, self.R_merged, self.omega,
                                      self.delta_input, eta_broadening)
        print(f"Chi squared (Frobenius): {chi:.6e}")
        print("--- End analysis ---")
        return self

    def plot_results(self):
        if self.delta_merged is None:
            print("Call run_fit first")
            return

        sel = (0, 0)
        tr_input = np.trace(self.delta_input, axis1=1, axis2=2)
        tr_lanczos = np.trace(self.delta_lanczos, axis1=1, axis2=2)
        tr_merged = np.trace(self.delta_merged, axis1=1, axis2=2)

        fig, axes = plt.subplots(2, 2, figsize=(14, 8), sharex=True)

        axes[0, 0].plot(self.omega, np.real(self.delta_input[:, sel[0], sel[1]]), 'k-', label='Input')
        axes[0, 0].plot(self.omega, np.real(self.delta_lanczos[:, sel[0], sel[1]]), 'r--', label='Lanczos')
        axes[0, 0].plot(self.omega, np.real(self.delta_merged[:, sel[0], sel[1]]), 'b:', lw=2, label='Merged')
        axes[0, 0].set_ylabel(f"Re Δ[{sel[0]},{sel[1]}]")
        axes[0, 0].set_title(f"Element [{sel[0]},{sel[1]}]")
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        axes[1, 0].plot(self.omega, np.imag(self.delta_input[:, sel[0], sel[1]]), 'k-')
        axes[1, 0].plot(self.omega, np.imag(self.delta_lanczos[:, sel[0], sel[1]]), 'r--')
        axes[1, 0].plot(self.omega, np.imag(self.delta_merged[:, sel[0], sel[1]]), 'b:', lw=2)
        axes[1, 0].set_xlabel("ω")
        axes[1, 0].set_ylabel(f"Im Δ[{sel[0]},{sel[1]}]")
        axes[1, 0].grid(True, alpha=0.3)

        axes[0, 1].plot(self.omega, np.real(tr_input), 'k-', label='Input')
        axes[0, 1].plot(self.omega, np.real(tr_lanczos), 'r--', label='Lanczos')
        axes[0, 1].plot(self.omega, np.real(tr_merged), 'b:', lw=2, label='Merged')
        axes[0, 1].set_ylabel("Re Tr Δ")
        axes[0, 1].set_title("Trace")
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        axes[1, 1].plot(self.omega, np.imag(tr_input), 'k-')
        axes[1, 1].plot(self.omega, np.imag(tr_lanczos), 'r--')
        axes[1, 1].plot(self.omega, np.imag(tr_merged), 'b:', lw=2)
        axes[1, 1].set_xlabel("ω")
        axes[1, 1].set_ylabel("Im Tr Δ")
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

    # ------------- helpers and internals -------------

    @staticmethod
    def load_delta_from_files(file_re, file_im, col_re=5, col_im=5):
        data_re = np.loadtxt(file_re)
        data_im = np.loadtxt(file_im)
        omega_re, re_vals = data_re[:, 0], data_re[:, col_re]
        omega_im, im_vals = data_im[:, 0], data_im[:, col_im]
        if not np.allclose(omega_re, omega_im, rtol=1e-12, atol=1e-14):
            raise ValueError("omega grids do not match")
        return omega_re.astype(float), (re_vals + 1j * im_vals).astype(np.complex128)

    def _fit_block_lanczos(self):
        print(f"1) Block Lanczos with trapezoid weights. Blocks = {self.n_lanczos_blocks}")

        # trapezoid weights on possibly non uniform grid
        dx = np.diff(self.omega)
        w = np.empty_like(self.omega)
        w[1:-1] = 0.5 * (dx[:-1] + dx[1:])
        w[0] = 0.5 * dx[0]
        w[-1] = 0.5 * dx[-1]

        rho_meas = -np.imag(self.delta_input) / np.pi
        mu_grid = [rho_meas[i] * w[i] for i in range(self.n_omega)]

        if self.block_size == -1:
            # collapse to scalar Gauss quadrature exactly like your script
            mu = np.array([float(M[0,0]) for M in mu_grid], dtype=np.float64)
            N = min(self.n_lanczos_blocks, self.n_omega)
            eps, wdiag, T = self._scalar_lanczos_quadrature(self.omega, mu, N)
            # lift back to block form
            self.eps_lanczos = eps
            self.R_lanczos = [np.array([[wj]], dtype=np.float64) for wj in wdiag]
            self.T_lanczos = T
            self.M0_sqrt_lanczos = np.array([[np.sqrt(mu.sum())]], dtype=np.float64)
            return

        A_blocks, B_blocks, _, M0 = self._block_lanczos_alg(
            x_vals=self.omega,
            weight_mats=mu_grid,
            K=self.n_lanczos_blocks,
            b=self.block_size
        )

        # guard: trim B if needed and build T of size (len(B)+1)*b
        if B_blocks and len(B_blocks) != len(A_blocks) - 1:
            B_blocks = B_blocks[:max(0, len(A_blocks) - 1)]

        self.T_lanczos = self._build_block_tridiagonal(A_blocks, B_blocks)
        self.M0_sqrt_lanczos = self._sym_sqrt_psd(M0)
        print(f"   T shape = {self.T_lanczos.shape}")

    def _extract_poles_from_T(self):
        if self.T_lanczos is None:
            raise RuntimeError("run _fit_block_lanczos first")

        print("2) Extracting poles and residues from T")
        if self.T_lanczos.size == 0:
            self.eps_lanczos, self.R_lanczos = np.array([]), []
            return

        evals, evecs = npl.eigh(self.T_lanczos)
        self.eps_lanczos = evals

        b = self.block_size
        n_T = self.T_lanczos.shape[0]
        E1 = np.zeros((n_T, b))
        E1[:b, :b] = np.eye(b)

        R = []
        for j in range(n_T):
            uj = evecs[:, j:j+1]                     # (n_T,1)
            vj = self.M0_sqrt_lanczos.T @ E1.T @ uj  # (b,1)
            Rj = vj @ vj.conj().T                    # PSD Hermitian
            R.append(Rj)
        self.R_lanczos = R
        print(f"   poles extracted = {len(self.eps_lanczos)}")

    def _merge_poles_block(self, kind="atan", w0=0.1):
        if self.eps_lanczos is None:
            raise RuntimeError("run _extract_poles_from_T first")
        print(f"3) Merging to {self.n_target_poles} poles using warp = {kind}, w0 = {w0}")
        self.eps_merged, self.R_merged = self._merge_poles_block_warped(
            self.eps_lanczos, self.R_lanczos, self.n_target_poles, kind=kind, w0=w0
        )

    @staticmethod
    def _delta_from_poles(z, eps, residues):
        z_arr = np.atleast_1d(np.asarray(z, dtype=np.complex128))
        if len(eps) == 0:
            # derive M if possible, else default to 1
            M = residues[0].shape[0] if len(residues) > 0 else 1
            out = np.zeros(z_arr.shape + (M, M), dtype=np.complex128)
            return out[0] if np.isscalar(z) else out

        M = residues[0].shape[0]
        out = np.zeros(z_arr.shape + (M, M), dtype=np.complex128)
        for j, ej in enumerate(eps):
            denom = (z_arr - ej)[..., None, None]
            out += residues[j][None, :, :] / denom
        return out[0] if np.isscalar(z) else out

    @staticmethod
    def _sym_sqrt_psd(A, tol=1e-12):
        A = 0.5 * (A + A.T.conj())
        w, Q = npl.eigh(A)
        w = np.clip(w, 0.0, None)
        return Q @ np.diag(np.sqrt(w)) @ Q.T.conj()

    @classmethod
    def _merge_poles_block_warped(cls, eps, R_list, n_target, kind="atan", w0=0.1):
        phi, inv = cls._make_warp(kind, w0)

        eps = np.asarray(eps, float).copy()
        R = list(R_list)

        order = np.argsort(eps)
        eps = eps[order]
        R = [R[i] for i in order]

        z = phi(eps)
        Tr_R = np.array([np.real(np.trace(Ri)) for Ri in R])

        while len(eps) > n_target:
            tr_prod = Tr_R[:-1] * Tr_R[1:]
            tr_sum = Tr_R[:-1] + Tr_R[1:]
            # variance loss in warped space with scalarization Tr(R)
            costs = (tr_prod / (tr_sum + 1e-300)) * (z[:-1] - z[1:])**2
            i = int(np.argmin(costs))

            R_new = R[i] + R[i+1]
            Tr_new = Tr_R[i] + Tr_R[i+1]

            if Tr_new < 1e-300:
                e_new = 0.5 * (eps[i] + eps[i+1])
            else:
                e_new = (eps[i] * Tr_R[i] + eps[i+1] * Tr_R[i+1]) / Tr_new

            z_new = phi(e_new)

            eps = np.concatenate([eps[:i], [e_new], eps[i+2:]])
            R = R[:i] + [R_new] + R[i+2:]
            Tr_R = np.concatenate([Tr_R[:i], [Tr_new], Tr_R[i+2:]])
            z = np.concatenate([z[:i], [z_new], z[i+2:]])

        return eps, R

    @staticmethod
    def _make_warp(kind="atan", w0=0.1):
        if kind == "atan":
            return (lambda x: np.arctan(x / w0), lambda y: w0 * np.tan(y))
        if kind == "asinh":
            return (lambda x: np.arcsinh(x / w0), lambda y: w0 * np.sinh(y))
        return (lambda x: x, lambda y: y)

    @staticmethod
    def _block_lanczos_alg(x_vals, weight_mats, K, b, tol=1e-12):
        """
        Robust block Lanczos with full reorthogonalization and rank aware steps.
        Inner product is <Φ,Ψ> = sum_i Φ_i^† μ_i Ψ_i, Hermitian symmetrized.
        """
        x_vals = np.asarray(x_vals, float)
        S = len(x_vals)
        M = weight_mats[0].shape[0]

        def blk_ip_grid(Phi, Psi, mu_list):
            # shapes: Phi, Psi -> (S,M,b); mu_list -> (S,M,M)
            mu = np.stack(mu_list, axis=0)                         # (S,M,M)
            acc = np.einsum('smi,smn,snj->ij', 
                            Phi.conj(), mu, Psi, optimize=True)    # (b,b)
            return 0.5*(acc + acc.conj().T)

        def _sqrt_and_pinv_from_gram(G):
            Gs = 0.5 * (G + G.conj().T)
            s, U = npl.eigh(Gs)
            s = np.clip(s, 0.0, None)
            smax = np.max(s) if s.size else 0.0
            thr = max(tol, smax * 1e-12)
            s_clipped = np.where(s > thr, s, 0.0)

            sqrt_s = np.zeros_like(s_clipped)
            pisqrt_s = np.zeros_like(s_clipped)
            mask = s_clipped > 0.0
            sqrt_s[mask] = np.sqrt(s_clipped[mask])
            pisqrt_s[mask] = 1.0 / sqrt_s[mask]

            B = U @ np.diag(sqrt_s) @ U.T.conj()
            B_pinv = U @ np.diag(pisqrt_s) @ U.T.conj()
            eff_rank = int(np.sum(mask))
            return B, B_pinv, eff_rank

        # M0
        M0 = np.zeros((M, M), dtype=np.complex128)
        for Wi in weight_mats:
            M0 += Wi
        M0 = 0.5 * (M0 + M0.conj().T)

        # starting block: identities orthonormalized
        Phi0_raw = np.zeros((S, M, b), dtype=np.complex128)
        for s in range(S):
            Phi0_raw[s] = np.eye(M, b, dtype=np.complex128)

        G0 = blk_ip_grid(Phi0_raw, Phi0_raw, weight_mats)
        _, B0_pinv, _ = _sqrt_and_pinv_from_gram(G0)
        Phi_i = Phi0_raw @ B0_pinv
        Phi_im1 = np.zeros_like(Phi_i)

        A_blocks, B_blocks, Phi_list = [], [], [Phi_i.copy()]
        B_im1 = np.zeros((b, b), dtype=np.complex128)

        for k in range(K):
            XPhi = x_vals[:, None, None] * Phi_i
            Ak = blk_ip_grid(Phi_i, XPhi, weight_mats)
            Ak = 0.5 * (Ak + Ak.conj().T)
            A_blocks.append(Ak)

            W = XPhi - Phi_i @ Ak - Phi_im1 @ B_im1.T.conj()

            # full reorthogonalization, two passes
            for _ in range(2):
                for P in Phi_list:
                    C = blk_ip_grid(P, W, weight_mats)
                    W = W - P @ C

            G = blk_ip_grid(W, W, weight_mats)
            Bk, Bk_pinv, eff_rank = _sqrt_and_pinv_from_gram(G)

            if eff_rank == 0:
                break

            if k < K - 1:
                B_blocks.append(Bk)
                Phi_ip1 = W @ Bk_pinv
                Phi_im1, Phi_i = Phi_i, Phi_ip1
                Phi_list.append(Phi_i.copy())
                B_im1 = Bk
            else:
                break

        return A_blocks, B_blocks, Phi_list, M0

    @staticmethod
    def _build_block_tridiagonal(A_blocks, B_blocks):
        if not A_blocks:
            return np.zeros((0, 0), dtype=float)

        b = A_blocks[0].shape[0]
        K_eff = len(B_blocks) + 1
        A_blocks = A_blocks[:K_eff]

        n = K_eff * b
        T = np.zeros((n, n), dtype=np.complex128)

        for k in range(K_eff):
            T[k*b:(k+1)*b, k*b:(k+1)*b] = A_blocks[k]
            if k < len(B_blocks):
                Bk = B_blocks[k]
                T[k*b:(k+1)*b, (k+1)*b:(k+2)*b] = Bk
                T[(k+1)*b:(k+2)*b, k*b:(k+1)*b] = Bk

        # return Hermitian real if blocks were real
        T = 0.5 * (T + T.conj().T)
        return np.real_if_close(T)

    @staticmethod
    def _scalar_lanczos_quadrature(x, mu, N):
        x = np.asarray(x, float); mu = np.asarray(mu, float)
        N = min(N, x.size)
        def ip(a,b): return float(np.dot(mu, a*b))
        def nrm(a): return np.sqrt(max(ip(a,a), 1e-300))
        v_im1 = np.zeros_like(x); v = np.ones_like(x); v /= nrm(v)
        al, be = [], []
        beta_im1 = 0.0
        for j in range(N):
            w = x*v
            a = ip(v,w); al.append(a)
            w = w - a*v - beta_im1*v_im1
            beta = nrm(w); 
            if j < N-1: be.append(beta)
            v_im1, v = v, w/(beta + 1e-300)
            beta_im1 = beta
        T = np.zeros((N,N))
        i = np.arange(N)
        T[i,i] = al
        j = np.arange(N-1)
        T[j, j+1] = be
        T[j+1, j] = be
        evals, evecs = npl.eigh(T)
        wdiag = mu.sum() * (evecs[0,:]**2)
        return evals, wdiag, T

    @staticmethod
    def _rel_l2_mat(F_true, F_rec):
        diff = F_true - F_rec
        num = np.sum(np.abs(diff)**2)
        den = np.sum(np.abs(F_true)**2) + 1e-300
        return np.sqrt(num / den)

    @classmethod
    def _cost_function_mat(cls, e, R, omega, target_delta, delta):
        model_delta = cls._delta_from_poles(omega + 1j * delta, e, R)
        diff = target_delta - model_delta
        return float(np.sum(np.abs(diff)**2))


if __name__ == "__main__":
    FILE_RE = "real-hyb-Ce4f.dat"
    FILE_IM = "imag-hyb-Ce4f.dat"
    N_LANCZOS_BLOCKS = 101
    N_TARGET_POLES = 3
    ETA_INPUT = 0.005

    try:
        omega_data, delta_data = HybridizationFitter.load_delta_from_files(FILE_RE, FILE_IM)
        fitter = HybridizationFitter(
            omega_grid=omega_data,
            delta_complex=delta_data,
            n_lanczos_blocks=N_LANCZOS_BLOCKS,
            n_target_poles=N_TARGET_POLES
        )
        fitter.run_fit(eta_broadening=ETA_INPUT).analyze(eta_broadening=ETA_INPUT)
        fitter.plot_results()
    except FileNotFoundError:
        print(f"Error. Missing {FILE_RE} or {FILE_IM}")
    except Exception as e:
        print(f"Unexpected error: {e}")
        import traceback
        traceback.print_exc()# gfs.py
import numpy as np
from . import clic_clib as cc
import scipy.sparse as sp
import numpy.linalg as npl
from numpy.linalg import norm

# -----------------------------
# Helpers: wavefunction <-> basis
# -----------------------------

def wavefunction_support(wf, coeff_thresh=1e-14):
    """
    Return the set of determinants in a Wavefunction with |coeff|>coeff_thresh.
    Assumes wf.data() is a mapping {SlaterDeterminant: complex}.
    """
    data = wf.data()
    return {det for det, c in data.items() if abs(c) > coeff_thresh}

def wf_to_vec(wf, basis_list):
    """
    Project wavefunction onto a given determinant basis ordering -> dense vector.
    """
    data = wf.data()
    idx = {det: k for k, det in enumerate(basis_list)}
    v = np.zeros(len(basis_list), dtype=np.complex128)
    for det, c in data.items():
        k = idx.get(det, None)
        if k is not None:
            v[k] += c
    return v

# -----------------------------
# Build fixed Krylov basis by repeated H-applications at determinant level
# -----------------------------

def expand_basis_by_H(seed_dets, one_body_terms, two_body_terms, NappH):
    """
    Determinant-level expansion:
    B_0 = seed_dets
    B_{t+1} = B_t ∪ H*B_t connections (via one- and two-body graph expansion)
    Stop after NappH expansions.
    """
    current = set(seed_dets)
    for _ in range(NappH):
        conn1 = cc.get_connections_one_body(list(current), one_body_terms)
        conn2 = cc.get_connections_two_body(list(current), two_body_terms)
        current |= set(conn1)
        current |= set(conn2)
    return sorted(list(current))

def build_sector_basis_from_seeds(seeds_wf, one_body_terms, two_body_terms, NappH, coeff_thresh=1e-14):
    """
    seeds_wf: list of seed Wavefunctions for a given particle sector.
    1) collect support determinants from all seeds
    2) expand that set by NappH applications of H
    """
    if not seeds_wf:
        return []
    seed_support = set()
    for wf in seeds_wf:
        seed_support |= wavefunction_support(wf, coeff_thresh=coeff_thresh)
    return expand_basis_by_H(seed_support, one_body_terms, two_body_terms, NappH)

# -----------------------------
# Hamiltonian restricted to a fixed determinant basis
# -----------------------------

def build_H_in_basis(basis_dets, h0_clean, U_clean):
    """
    Use your fast OpenMP builder on the restricted basis.
    Returns a scipy.spmatrix (CSR).
    """
    if len(basis_dets) == 0:
        return sp.csr_matrix((0,0), dtype=np.complex128)
    H = cc.build_hamiltonian_openmp(basis_dets, h0_clean, U_clean)
    return H

# -----------------------------
# Block Lanczos on a fixed basis with dense/sparse @
# -----------------------------

def gram_schmidt_qr_dense(block_V, reorth=False, eps=1e-20):
    """
    Gram-Schmidt QR on a list of dense vectors (numpy arrays), returns (Q_list, R).
    Q_list contains orthonormal dense vectors (same length as v).
    R has shape (len(Q_list), n). If columns are dependent, len(Q_list) < n.
    """
    n = len(block_V)
    if n == 0:
        return [], np.array([[]], dtype=np.complex128)
    # Copy inputs
    V = [v.astype(np.complex128, copy=True) for v in block_V]
    Q = []
    R = np.zeros((n, n), dtype=np.complex128)
    for j in range(n):
        vj = V[j]
        for i, qi in enumerate(Q):
            hij = np.vdot(qi, vj)
            R[i, j] = hij
            vj -= hij * qi
        if reorth and len(Q):
            # one extra pass
            for i, qi in enumerate(Q):
                hij = np.vdot(qi, vj)
                R[i, j] += hij
                vj -= hij * qi
        nrm2 = np.vdot(vj, vj).real
        if nrm2 > eps:
            nrm = np.sqrt(nrm2)
            R[j, j] = nrm
            Q.append(vj / nrm)
        else:
            break
    r = len(Q)
    return Q, R[:r, :n]

def block_lanczos_fixed_basis(H, seed_vecs, L, reorth=False):
    """
    Standard block-Lanczos where H is a matrix in the fixed basis (dense or sparse),
    and seed_vecs is a list of dense vectors (already in that basis).
    Returns As, Bs, Qblocks, R0, where:
      - Qblocks[k] is a list of orthonormal vectors (columns) at block k
      - As[k], Bs[k] are the small block matrices like in your previous routine
    """
    Q0, R0 = gram_schmidt_qr_dense(seed_vecs, reorth=reorth)
    if len(Q0) == 0:
        return [], [], [], R0

    # Convert block list to column-block matrix helpers
    def block_to_mat(Qblock):
        return np.column_stack(Qblock) if len(Qblock) else np.zeros((H.shape[0], 0), dtype=np.complex128)

    Qblocks = [Q0]
    As, Bs = [], []

    Qk = block_to_mat(Q0)
    HQk = H @ Qk
    Ak = Qk.conj().T @ HQk
    As.append(Ak)

    Qkm1 = np.zeros((H.shape[0], 0), dtype=np.complex128)  # empty previous block

    for _ in range(L):
        # W = H Qk - Qk Ak - Q_{k-1} B_{k-1}^H
        W = HQk - Qk @ Ak
        if len(Bs) > 0:
            W -= Qkm1 @ Bs[-1].conj().T

        # Orthonormalize W
        W_cols = [W[:, j].copy() for j in range(W.shape[1])]
        Qnext_list, Bk = gram_schmidt_qr_dense(W_cols, reorth=reorth)
        if len(Qnext_list) == 0:
            break

        Bs.append(Bk)
        Qkm1 = Qk
        Qk = np.column_stack(Qnext_list)

        # Update Ak+1
        HQk = H @ Qk
        Ak = Qk.conj().T @ HQk
        As.append(Ak)

        Qblocks.append(Qnext_list)

    return As, Bs, Qblocks, R0

# -----------------------------
# Continued fraction for top-left block (unchanged)
# -----------------------------

def block_cf_top_left(As, Bs, z):
    """
    Evaluate the top left block of the block tridiagonal resolvent using a
    backward continued fraction with linear solves.
    """
    if not As:
        return np.array([[]], dtype=np.complex128)
    m0 = As[0].shape[0]
    Id0 = np.eye(m0, dtype=np.complex128)
    Sigma = np.zeros_like(As[-1], dtype=np.complex128)
    for k in range(len(As) - 2, -1, -1):
        Bkp1 = Bs[k]
        Ikp1 = np.eye(As[k+1].shape[0], dtype=np.complex128)
        try:
            # Solve (z I - A_{k+1} - Sigma) X = B rather than invert
            X = npl.solve(z * Ikp1 - As[k+1] - Sigma, Bkp1)
        except npl.LinAlgError:
            return np.full_like(Id0, np.nan)
        Sigma = Bkp1.conj().T @ X
    try:
        return npl.solve(z * Id0 - As[0] - Sigma, np.eye(m0, dtype=np.complex128))
    except npl.LinAlgError:
        return np.full_like(Id0, np.nan)

# -----------------------------
# Top-level: fixed-basis block-Lanczos Green's function
# -----------------------------

def green_function_block_lanczos_fixed_basis(
    M, psi0_wf, e0, ws, eta, impurity_indices, NappH,
    h0_clean, U_clean, one_body_terms, two_body_terms, coeff_thresh=1e-12, L=100, reorth=False
):
    """
    For each sector (N+1 and N-1):
      1) Build seed wavefunctions by applying creation/annihilation on psi0
      2) Build fixed Krylov determinant basis by NappH H-expansions
      3) Build H_in_basis once
      4) Run block-Lanczos using plain matrix multiplications with H_in_basis
      5) Assemble G(ω) on the subspace of selected impurity indices, embedded back
         into the full spin-orbital space (size 2M), like your previous routine.
    """
    Norb = 2*M
    Nw = len(ws)

    # 1) seeds in each sector, keep maps to the global spin-orbital indices
    seed_add_wf, add_src_idx = [], []
    seed_rem_wf, rem_src_idx = [], []
    for i in impurity_indices:
        si = cc.Spin.Alpha if i < M else cc.Spin.Beta
        oi = i % M
        wa = cc.apply_creation(psi0_wf, oi, si)
        if wa.data():  # non-empty
            seed_add_wf.append(wa)
            add_src_idx.append(i)
        wr = cc.apply_annihilation(psi0_wf, oi, si)
        if wr.data():
            seed_rem_wf.append(wr)
            rem_src_idx.append(i)

    # 2) fixed determinant bases
    basis_add = build_sector_basis_from_seeds(seed_add_wf, one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh)
    basis_rem = build_sector_basis_from_seeds(seed_rem_wf, one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh)

    # 3) build H in those bases
    H_add = build_H_in_basis(basis_add, h0_clean, U_clean) if len(basis_add) else sp.csr_matrix((0,0), dtype=np.complex128)
    H_rem = build_H_in_basis(basis_rem, h0_clean, U_clean) if len(basis_rem) else sp.csr_matrix((0,0), dtype=np.complex128)

    # 4) initial block vectors Q0 in each sector: project seeds to the fixed bases
    seed_vecs_add = [wf_to_vec(wf, basis_add) for wf in seed_add_wf] if len(basis_add) else []
    seed_vecs_rem = [wf_to_vec(wf, basis_rem) for wf in seed_rem_wf] if len(basis_rem) else []

    # Run block-Lanczos on the fixed bases
    As_g, Bs_g, Qs_g, R0_g = ([], [], [], np.array([]))
    As_l, Bs_l, Qs_l, R0_l = ([], [], [], np.array([]))

    # Drop a sector if all projected seeds are numerically zero
    if seed_vecs_add and all(norm(v) < 1e-30 for v in seed_vecs_add):
        seed_vecs_add, add_src_idx, basis_add, H_add = [], [], [], sp.csr_matrix((0,0), dtype=np.complex128)
    if seed_vecs_rem and all(norm(v) < 1e-30 for v in seed_vecs_rem):
        seed_vecs_rem, rem_src_idx, basis_rem, H_rem = [], [], [], sp.csr_matrix((0,0), dtype=np.complex128)

    if len(seed_vecs_add):
        # convert CSR to linear operator by dense/sparse @ in the iteration
        As_g, Bs_g, Qs_g, R0_g = block_lanczos_fixed_basis(H_add, seed_vecs_add, L=L, reorth=reorth)

    if len(seed_vecs_rem):
        As_l, Bs_l, Qs_l, R0_l = block_lanczos_fixed_basis(H_rem, seed_vecs_rem, L=L, reorth=reorth)

    have_g = (R0_g.size != 0 and len(As_g) > 0)
    have_l = (R0_l.size != 0 and len(As_l) > 0)

    # Indices in the small blocks correspond one-to-one to the surviving seeds order
    # We preserved the mapping to the global spin-orbital indices in add_src_idx and rem_src_idx

    # 5) Evaluate G(ω) in the seed subspace and embed back to [Norb x Norb] using the preserved maps
    G_all = np.zeros((Nw, Norb, Norb), dtype=np.complex128)

    for iw, w in enumerate(ws):
        z_g = (w + e0) + 1j*eta
        z_l = (-w + e0) - 1j*eta

        Gg_eff = None
        if have_g:
            G00_g = block_cf_top_left(As_g, Bs_g, z_g)
            if G00_g.size != 0 and not np.isnan(G00_g).any():
                # Note: here R0_g is the QR R factor. The "impurity block" in this fixed-basis variant
                #       corresponds to the seed subspace, so the correct coupling into CF top-left is
                #       exactly like before: G_eff = R^H G00 R.
                Gg_eff = R0_g.conj().T @ G00_g @ R0_g

        Gl_eff = None
        if have_l:
            G00_l = block_cf_top_left(As_l, Bs_l, z_l)
            if G00_l.size != 0 and not np.isnan(G00_l).any():
                Gl_eff = R0_l.conj().T @ G00_l @ R0_l

        # place back into the full Norb x Norb with the seed ordering matching impurity_indices
        # but only for those seeds that actually survived
        if Gg_eff is not None:
            for a, ia in enumerate(add_src_idx):
                for b, ib in enumerate(add_src_idx):
                    G_all[iw, ia, ib] += Gg_eff[a, b]

        if Gl_eff is not None:
            for a, ia in enumerate(rem_src_idx):
                for b, ib in enumerate(rem_src_idx):
                    G_all[iw, ia, ib] -= Gl_eff[a, b]

    return G_all, dict(
        basis_add_size=len(basis_add), basis_rem_size=len(basis_rem),
        have_g=have_g, have_l=have_l
    )


def green_function_scalar_fixed_basis(
    M, psi0_wf, e0, ws, eta, i, NappH,
    h0_clean, U_clean, one_body_terms, two_body_terms,
    coeff_thresh=1e-12, L=100, reorth=False
):
    """
    Compute the single-diagonal element G_ii(ω) for a given spin-orbital index i (0..2M-1)
    using the fixed-basis block-Lanczos approach specialized to a scalar seed subspace.

    Returns
    -------
    Gii : np.ndarray of shape (Nw,), complex128
        The diagonal Green's function element G_ii(ω) for each ω in `ws`.
    info : dict
        Diagnostics: sizes of addition/removal bases, flags for having each sector, etc.
    """
    Norb = 2*M
    assert 0 <= i < Norb, "i must be in [0, 2M)"

    Nw = len(ws)
    Gii = np.zeros(Nw, dtype=np.complex128)

    # --- Build the two sector seeds only for index i
    si = cc.Spin.Alpha if i < M else cc.Spin.Beta
    oi = i % M

    wf_add = cc.apply_creation(psi0_wf, oi, si)
    wf_rem = cc.apply_annihilation(psi0_wf, oi, si)

    have_add_seed = bool(wf_add.data())
    have_rem_seed = bool(wf_rem.data())

    # Early exit if both seeds vanish (matrix element zero)
    if not have_add_seed and not have_rem_seed:
        return Gii, dict(
            basis_add_size=0, basis_rem_size=0,
            have_g=False, have_l=False,
            seed_nonzero=False
        )

    # --- Determinant bases by H-expansion from the single seeds
    basis_add = build_sector_basis_from_seeds(
        [wf_add] if have_add_seed else [],
        one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh
    )
    basis_rem = build_sector_basis_from_seeds(
        [wf_rem] if have_rem_seed else [],
        one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh
    )

    # --- Restrict H
    H_add = build_H_in_basis(basis_add, h0_clean, U_clean) if len(basis_add) else sp.csr_matrix((0,0), dtype=np.complex128)
    H_rem = build_H_in_basis(basis_rem, h0_clean, U_clean) if len(basis_rem) else sp.csr_matrix((0,0), dtype=np.complex128)

    # --- Project seeds into their bases (each is a single dense vector)
    seed_vecs_add = [wf_to_vec(wf_add, basis_add)] if have_add_seed and len(basis_add) else []
    seed_vecs_rem = [wf_to_vec(wf_rem, basis_rem)] if have_rem_seed and len(basis_rem) else []

    # Drop sector if the projected seed is numerically zero after expansion
    if seed_vecs_add and norm(seed_vecs_add[0]) < 1e-30:
        seed_vecs_add = []
    if seed_vecs_rem and norm(seed_vecs_rem[0]) < 1e-30:
        seed_vecs_rem = []

    # --- Block Lanczos in each sector (block size will be 1 if present)
    As_g, Bs_g, R0_g = [], [], np.array([])
    As_l, Bs_l, R0_l = [], [], np.array([])

    if seed_vecs_add:
        As_g, Bs_g, _, R0_g = block_lanczos_fixed_basis(H_add, seed_vecs_add, L=L, reorth=reorth)

    if seed_vecs_rem:
        As_l, Bs_l, _, R0_l = block_lanczos_fixed_basis(H_rem, seed_vecs_rem, L=L, reorth=reorth)

    have_g = (R0_g.size != 0 and len(As_g) > 0)
    have_l = (R0_l.size != 0 and len(As_l) > 0)

    # --- Evaluate scalar CFs and assemble G_ii(ω) = (R* G00 R)_{00}^add - (R* G00 R)_{00}^rem
    # For 1x1 blocks: G_eff = |R0|^2 * G00
    for iw, w in enumerate(ws):
        # particle sector: z_g = w + e0 + iη
        if have_g:
            z_g = (w + e0) + 1j*eta
            G00_g = block_cf_top_left(As_g, Bs_g, z_g)  # shape (1,1)
            if G00_g.size and not np.isnan(G00_g).any():
                r = R0_g[0, 0] if R0_g.ndim == 2 else R0_g
                Gii[iw] += (abs(r)**2) * G00_g[0, 0]

        # hole sector: z_l = -w + e0 - iη
        if have_l:
            z_l = (-w + e0) - 1j*eta
            G00_l = block_cf_top_left(As_l, Bs_l, z_l)  # shape (1,1)
            if G00_l.size and not np.isnan(G00_l).any():
                r = R0_l[0, 0] if R0_l.ndim == 2 else R0_l
                Gii[iw] -= (abs(r)**2) * G00_l[0, 0]

    return Gii, dict(
        basis_add_size=len(basis_add), basis_rem_size=len(basis_rem),
        have_g=have_g, have_l=have_l, seed_nonzero=True
    )


# ---------------------------------------------------------------------------
# TIME PROPAGATION 
# ---------------------------------------------------------------------------

def _lanczos_tridiagonal(H, v0, L=200, reorth=False):
    """
    Perform Hermitian Lanczos iteration starting from vector v0.
    Constructs an orthonormal Krylov basis Q and the tridiagonal matrix T.

    Parameters
    ----------
    H : (N×N) linear operator (csr_matrix or LinearOperator)
        Hermitian Hamiltonian, must support `@` for matrix-vector product.
    v0 : ndarray (N,)
        Initial vector to start the Krylov subspace.
    L : int
        Maximum number of Lanczos steps.
    reorth : bool
        If True, apply a (single-pass) reorthogonalization against all previous vectors
        to improve numerical stability.

    Returns
    -------
    Q : ndarray (N×m)
        Orthonormal Lanczos basis vectors.
    T : ndarray (m×m)
        Tridiagonal Lanczos matrix.
    v0_norm : float
        Norm of the initial vector v0.
    """

    # Ensure v0 is a complex128 array
    v0 = np.asarray(v0, dtype=np.complex128)
    N = v0.size

    # Normalize the initial vector
    v0_norm = np.linalg.norm(v0)
    if v0_norm == 0:
        # If v0 is zero, return empty basis and matrix
        return np.zeros((N,0), dtype=np.complex128), np.zeros((0,0), dtype=np.complex128), 0.0

    # Initialize first basis vector q = v0 / ||v0||
    q_prev = np.zeros_like(v0)   # "ghost" previous vector, initially zero
    q = v0 / v0_norm
    Qcols = [q.copy()]           # list to store basis vectors
    alphas, betas = [], []       # diagonals and off-diagonals of T

    beta = 0.0
    for _ in range(L):
        # Apply Hamiltonian
        w = H @ q
        # Rayleigh quotient α = <q|H|q>
        alpha = np.vdot(q, w)
        # Remove components along current and previous q (three-term recurrence)
        w = w - alpha * q - beta * q_prev

        # Optional reorthogonalization against all previous Q vectors
        if reorth and Qcols:
            Qmat = np.column_stack(Qcols)
            w -= Qmat @ (Qmat.conj().T @ w)

        # Next off-diagonal β = ||w||
        beta = np.linalg.norm(w)
        alphas.append(alpha)

        # If β ≈ 0, Krylov subspace has closed (breakdown)
        if beta < 1e-14:
            break

        # Store β and normalize new q
        betas.append(beta)
        q_prev, q = q, w / beta
        Qcols.append(q.copy())

    # Number of steps actually performed
    m = len(alphas)
    if m == 0:
        # Should not normally happen, but guard against empty Krylov space
        return np.zeros((N,0), dtype=np.complex128), np.zeros((0,0), dtype=np.complex128), v0_norm

    # Construct Q matrix (columns are q0, q1, …, q_{m-1})
    Q = np.column_stack(Qcols[:m])

    # Construct tridiagonal T from α and β coefficients
    T = np.zeros((m, m), dtype=np.complex128)
    for k in range(m):
        T[k, k] = alphas[k]      # diagonal entries
        if k+1 < m:
            T[k, k+1] = betas[k] # upper diagonal
            T[k+1, k] = betas[k] # lower diagonal

    return Q, T, v0_norm

def lanczos_tridiagonal_stable(H, v0, L=200, reorth=True, symmetrize=True, scale=True,
                               reorth_tol=1e-10, breakdown_tol=1e-14, powerit=20):
    """
    Hermitian Lanczos with optional symmetrization, spectral scaling, and two-pass MGS reorth.
    Returns Q (N×m), T (m×m), ||v0||.
    """

    # optional symmetrization
    if symmetrize:
        if sp.issparse(H):
            H = 0.5*(H + H.conj().T)
            H.setdiag(H.diagonal().real)
        else:
            H = 0.5*(H + H.conj().T)
            np.fill_diagonal(H, np.real(np.diag(H)))

    # estimate spectral radius for scaling
    rho = 1.0
    if scale:
        # power iteration on a random unit vector
        rng = np.random.default_rng(12345)
        x = rng.standard_normal(H.shape[0]) + 1j*rng.standard_normal(H.shape[0])
        x /= norm(x)
        n = 1.0
        for _ in range(powerit):
            x = H @ x
            n = norm(x)
            if not np.isfinite(n) or n < 1e-300:
                break
            x /= n
        rho = max(n, 1.0, 1e-12)
    Hdot = (lambda x: (H @ x) / rho) if scale else (lambda x: H @ x)

    v0 = np.asarray(v0, dtype=np.complex128)
    N = v0.size
    v0_norm = norm(v0)
    if v0_norm == 0.0:
        return np.zeros((N,0), np.complex128), np.zeros((0,0), np.complex128), 0.0

    q_prev = np.zeros_like(v0)
    q = v0 / v0_norm

    # preallocate Q with an upper bound of L+1 columns
    Q = np.empty((N, L+1), dtype=np.complex128)
    Q[:, 0] = q
    k = 0
    alphas = np.empty(L, dtype=np.float64)
    betas  = np.empty(L, dtype=np.float64)

    beta = 0.0
    while k < L:
        w = Hdot(q)
        alpha = np.vdot(q, w)
        # Hermitian guard: take the real part
        alpha = float(np.real(alpha))
        # three term recurrence
        w = w - alpha*q - beta*q_prev

        # selective reorth trigger
        if reorth:
            # test loss of orthogonality: max|Q[:,:k+1]^H w|
            hk = Q[:, :k+1].conj().T @ w
            maxlost = np.max(np.abs(hk))
            if maxlost > reorth_tol*norm(w):
                # two-pass MGS
                w -= Q[:, :k+1] @ hk
                hk2 = Q[:, :k+1].conj().T @ w
                w -= Q[:, :k+1] @ hk2

        beta = norm(w)
        alphas[k] = alpha

        if not np.isfinite(beta) or beta < breakdown_tol:
            # happy breakdown or numerical failure
            break

        q_prev, q = q, w / beta
        k += 1
        Q[:, k] = q
        betas[k-1] = beta

    m = max(1, k)  # at least one alpha
    Q = Q[:, :m]
    T = np.zeros((m, m), dtype=np.complex128)
    for i in range(m):
        # scale back the spectrum if we scaled H
        T[i, i] = alphas[i]*rho
        if i+1 < m:
            T[i, i+1] = betas[i]*rho
            T[i+1, i] = betas[i]*rho

    return Q, T, v0_norm

def green_function_from_time_propagation(
    i, j,
    M, psi0_wf, e0, ws, eta, impurity_indices, NappH,
    h0_clean, U_clean, one_body_terms, two_body_terms,
    coeff_thresh=1e-12, L=100, reorth=True
):
    """
    Compute the retarded Green's function G_ij(ω) using time propagation + Lanczos.

    Strategy:
      - Build N+1 and N-1 sector bases starting from |a_j> = c_j†|ψ0> and |r_j> = c_j|ψ0>.
      - Restrict H to those bases and shift by E0 so ground state is stationary.
      - Run Lanczos on each sector to get tridiagonal T matrices.
      - Use T’s spectral decomposition to compute time overlaps S_add(t), S_rem(t).
      - Fourier-integrate with damping exp(-ηt) to get G_ij(ω).

    Parameters
    ----------
    i, j : int
        Indices of the Green's function G_ij(ω) to compute (0 ≤ i,j < 2M).
    M : int
        Number of spatial orbitals (so Norb = 2M including spin).
    psi0_wf : Wavefunction
        Ground state wavefunction.
    e0 : float
        Ground state energy.
    ws : ndarray
        Frequency grid.
    eta : float
        Broadening parameter (imaginary shift).
    impurity_indices : list[int]
        Indices of impurity orbitals (not directly needed here).
    NappH : int
        Number of H-applications to expand determinant basis.
    h0_clean, U_clean, one_body_terms, two_body_terms :
        Hamiltonian input data.
    coeff_thresh : float
        Threshold for determinant coefficients.
    L : int
        Maximum Lanczos steps.
    reorth : bool
        Reorthogonalize Lanczos vectors.

    Returns
    -------
    g : ndarray (len(ws),)
        Complex retarded Green's function values at given ω grid.
    """

    ws = np.asarray(ws, dtype=float)
    Norb = 2*M
    assert 0 <= i < Norb and 0 <= j < Norb

    # Helper: convert global index to (orbital, spin)
    def _index_to_spin_orb(i, M):
        si = cc.Spin.Alpha if i < M else cc.Spin.Beta
        oi = i % M
        return oi, si

    # Spin/orbital for indices i and j
    oj, sj = _index_to_spin_orb(j, M)
    oi, si = _index_to_spin_orb(i, M)

    # Seeds: |a_j> = c_j†|ψ0>, |r_j> = c_j|ψ0>
    wf_add_j = cc.apply_creation(psi0_wf, oj, sj)
    wf_rem_j = cc.apply_annihilation(psi0_wf, oj, sj)
    have_add = bool(wf_add_j.data()); have_rem = bool(wf_rem_j.data())
    if not have_add and not have_rem:
        # If both vanish, G_ij(ω) = 0
        return np.zeros_like(ws, dtype=np.complex128)

    # Bra seeds for overlap evaluation (|a_i>, |r_i>)
    wf_add_i = cc.apply_creation(psi0_wf, oi, si)
    wf_rem_i = cc.apply_annihilation(psi0_wf, oi, si)

    # Build determinant bases for N+1 and N-1 sectors by H-expansion
    basis_add = build_sector_basis_from_seeds(
        [wf_add_j] if have_add else [], one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh
    )
    basis_rem = build_sector_basis_from_seeds(
        [wf_rem_j] if have_rem else [], one_body_terms, two_body_terms, NappH, coeff_thresh=coeff_thresh
    )

    # Build restricted Hamiltonians
    H_add = build_H_in_basis(basis_add, h0_clean, U_clean) if have_add and len(basis_add) else sp.csr_matrix((0,0), dtype=np.complex128)
    H_rem = build_H_in_basis(basis_rem, h0_clean, U_clean) if have_rem and len(basis_rem) else sp.csr_matrix((0,0), dtype=np.complex128)

    # Shift by ground state energy e0 so the ground state is stationary
    if H_add.shape[0] > 0:
        H_add = H_add - e0 * sp.eye(H_add.shape[0], dtype=np.complex128, format='csr')
    if H_rem.shape[0] > 0:
        H_rem = H_rem - e0 * sp.eye(H_rem.shape[0], dtype=np.complex128, format='csr')

    # Project seeds into those bases
    a_j_vec = wf_to_vec(wf_add_j, basis_add) if have_add and H_add.shape[0] else np.zeros((0,), dtype=np.complex128)
    r_j_vec = wf_to_vec(wf_rem_j, basis_rem) if have_rem and H_rem.shape[0] else np.zeros((0,), dtype=np.complex128)
    a_i_vec = wf_to_vec(wf_add_i, basis_add) if have_add and H_add.shape[0] else np.zeros((0,), dtype=np.complex128)
    r_i_vec = wf_to_vec(wf_rem_i, basis_rem) if have_rem and H_rem.shape[0] else np.zeros((0,), dtype=np.complex128)

    # Lanczos on each sector starting from |a_j>, |r_j>
    Qp=Tp=n0p=None; Qm=Tm=n0m=None
    if have_add and a_j_vec.size:
        # stable variant with symmetrization and spectral scaling
        Qp, Tp, n0p = lanczos_tridiagonal_stable(H_add, a_j_vec, L=L, reorth=True, symmetrize=True, scale=True)
    if have_rem and r_j_vec.size:
        Qm, Tm, n0m = lanczos_tridiagonal_stable(H_rem, r_j_vec, L=L, reorth=True, symmetrize=True, scale=True)

    # Helper: pick time grid from ws and η
    def _compute_time_grid(ws, eta):
        ws = np.asarray(ws, dtype=float)
        wmin, wmax = ws.min(), ws.max()
        span = max(wmax - wmin, 1e-6)
        # target time scales: from η and from frequency spacing
        t_eta = 8.0 / max(eta, 1e-6)
        dw = np.median(np.diff(np.unique(np.round(ws, 12)))) if ws.size > 1 else span
        t_dw = 2.0*np.pi / max(dw, 1e-6)
        t_max = max(t_eta, t_dw)
        # dt to avoid aliasing: dt ≲ π/(4Ω)
        wabs = max(abs(wmin), abs(wmax), 1.0)
        dt_alias = np.pi / (4.0 * wabs)
        dt = min(dt_alias, t_max/4096.0)
        # clamp Nt between 512 and 8192
        Nt = int(min(max(np.ceil(t_max/dt), 512), 8192))
        ts = dt * np.arange(Nt, dtype=float)
        return ts, dt

    ts, dt = _compute_time_grid(ws, eta)

    # Helper: compute time overlaps S(t) = <bra| exp(i sign T t) e1 > * v0_norm
    def _time_overlaps_from_lanczos(T, Q, bra_vec, v0_norm, ts, sign):
        if T is None or T.size == 0:
            return np.zeros_like(ts, dtype=np.complex128)
        # Project bra onto Lanczos basis
        c = Q.conj().T @ bra_vec  # coefficients in Lanczos basis
        # Diagonalize small tridiagonal T
        evals, U = np.linalg.eigh(T)
        # e1 = (1,0,0,…)
        e1 = np.zeros((T.shape[0],), dtype=np.complex128); e1[0] = 1.0
        Udag_e1 = U.conj().T @ e1         # components of e1 in eigenbasis
        cdag_U  = np.conj(c) @ U          # bra projected in eigenbasis
        # Time evolution exp(i sign λ t) for each eigenvalue
        phases = np.exp(1j * sign * np.outer(evals, ts))   # (m, Nt)
        # Overlap sum
        return v0_norm * (cdag_U[:,None] * Udag_e1[:,None] * phases).sum(axis=0)

    # Time overlaps for addition (sign=-1) and removal (sign=+1)
    S_add = _time_overlaps_from_lanczos(Tp, Qp, a_i_vec, n0p, ts, sign=-1) if Qp is not None else np.zeros_like(ts, dtype=np.complex128)
    S_rem = _time_overlaps_from_lanczos(Tm, Qm, r_i_vec, n0m, ts, sign=+1) if Qm is not None else np.zeros_like(ts, dtype=np.complex128)

    # Fourier integration to G(ω): retarded integral with damping exp(-ηt)
    phase = np.exp(1j * np.outer(ws, ts)) * np.exp(-eta * ts)[None, :]
    g = -1j * dt * (phase @ (S_add + S_rem))  # -i factor for retarded GF

    return g# hamiltonians.py
import numpy as np 
from . import clic_clib as cc
import scipy.sparse
import h5py
from .basis_1p import double_h,umo2so,transform_integrals_interleaved_to_alphafirst

# --- Integral Generation for Anderson Impurity Model ---
def get_impurity_integrals(M, u, e_bath, V_bath, mu):
    """Builds the one- and two-electron integrals for the Anderson Impurity Model.

        This function sets up the Hamiltonian terms in the spin-orbital basis,
        where alpha-spin orbitals are indexed first, followed by beta-spin orbitals.

        Args:
            M (int): Total number of spatial orbitals (impurity + bath).
            u (float): The on-site Hubbard interaction for the impurity orbital.
            e_bath (np.ndarray): Array of energies for the bath orbitals.
            V_bath (np.ndarray): Array of hybridization strengths between the
                                impurity and bath orbitals.
            mu (float): The chemical potential.

        Returns:
            tuple[np.ndarray, np.ndarray]: A tuple containing:
                - **h0** (np.ndarray): The (2M, 2M) one-electron integral matrix.
                - **U** (np.ndarray): The (2M, 2M, 2M, 2M) two-electron integral tensor.
    """
    K = 2 * M
    h_spatial = np.zeros((M, M))
    diagonal_elements = np.concatenate(([-mu], e_bath))
    np.fill_diagonal(h_spatial, diagonal_elements)
    h_spatial[0, 1:] = V_bath
    h_spatial[1:, 0] = np.conj(V_bath)

    h0 = np.zeros((K, K))
    h0[0:M, 0:M] = h_spatial
    h0[M:K, M:K] = h_spatial
    
    U = np.zeros((K, K, K, K))
    imp_alpha_idx, imp_beta_idx = 0, M
    U[imp_alpha_idx, imp_beta_idx, imp_alpha_idx, imp_beta_idx] = u
    U[imp_beta_idx, imp_alpha_idx, imp_beta_idx, imp_alpha_idx] = u

    h0 = np.ascontiguousarray(h0, dtype=np.complex128)
    U = np.ascontiguousarray(U, dtype=np.complex128)
    return h0, U


def create_hubbard_V(M, U_val):
    """Builds the hubbard two-electron integrals in the spin-orbital basis,
        where alpha-spin orbitals are indexed first, followed by beta-spin orbitals.

        Args:
            M (int): Total number of spatial orbitals
            U_val (float): The on-site Hubbard interaction

        Returns:
            np.ndarray: The (2M, 2M, 2M, 2M) two-electron integral tensor.
    """
    K = 2 * M
    V = np.zeros((K, K, K, K), dtype=np.complex128)
    for i in range(M):
        alpha_i = i
        beta_i  = i + M
        V[alpha_i, beta_i, alpha_i, beta_i] = 2.0 * U_val
    V = np.ascontiguousarray(V, dtype=np.complex128)
    return V


def get_hubbard_dimer_ed_ref(t, U, M):
    K = 2 * M
    c_dag = [cc.get_creation_operator(K, i + 1) for i in range(K)]
    c = [cc.get_annihilation_operator(K, i + 1) for i in range(K)]
    H = scipy.sparse.csr_matrix((2**K, 2**K), dtype=np.complex128)
    if M == 2:
        H += -t * (c_dag[0] @ c[1] + c_dag[1] @ c[0])
        H += -t * (c_dag[0+M] @ c[1+M] + c_dag[1+M] @ c[0+M])
    for i in range(M):
        n_up = c_dag[i] @ c[i]
        n_down = c_dag[i+M] @ c[i+M]
        H += U * (n_up @ n_down)
    return H


# ---

def load_spatial_integrals(filename):
    """Loads spatial integrals and metadata from an HDF5 file."""
    try:
        with h5py.File(filename, "r") as f:
            hcore = f["h0"][:]
            ee = f["U"][:]
    except FileNotFoundError:
        raise RuntimeError(f"Integral file not found at: {filename}")
    except KeyError as e:
        raise RuntimeError(f"Missing key {e} in integral file '{filename}'. Expecting 'h0' and 'U'.")

    M = hcore.shape[0]
    print(f"Loaded spatial integrals from {filename}: M = {M}")
    return hcore, ee, M

def get_integrals_from_file(filepath: str, spin_structure: str): # <-- Add new argument
    """
    Main orchestrator function to load integrals from a file
    and convert them to the required spin-orbital format (AlphaFirst).
    Handles both spatial and spin-orbital integral sources.
    """
    with h5py.File(filepath, "r") as f:
        # Accept either "h0" or "h02solve"
        # --- DEBUGGING STEP: Print all available keys in the HDF5 file ---
        print(f"--- Contents of HDF5 file: {filepath} ---")
        available_keys = list(f.keys())
        print("Available top-level datasets/groups:", available_keys)
        print("---------------------------------------------")
        # --------------------------------------------------------------------
        if "h0" in f:
            h0_raw = f["h0"][:]
        elif "h02solve" in f:
            h0_raw = f["h02solve"][:]
        else:
            raise KeyError("No 'h0' or 'h02solve' dataset found in HDF5 file.")

        # Same for U, maybe allow "U" or "U2solve"
        if "U" in f:
            U_raw = f["U"][:]
        elif "U2solve" in f:
            U_raw = f["U2solve"][:]
        else:
            raise KeyError("No 'U' or 'U2solve' dataset found in HDF5 file.")
    
    M = h0_raw.shape[0] // 2 if spin_structure != "spatial" else h0_raw.shape[0]
    print(f"Loaded raw integrals from {filepath}: M_spatial = {M}, spin_structure = '{spin_structure}'")

    # 2. Perform necessary basis transformations
    if spin_structure == "spatial":
        print(" -> Converting spatial integrals to AlphaFirst spin-orbital basis...")
        # hcore (M, M) -> h0 (2M, 2M)
        h0_spin_orbital = double_h(h0_raw, M)
        # U_spatial (M,M,M,M) -> U (2M,2M,2M,2M)
        U_spin_orbital = umo2so(U_raw, M)
    
    elif spin_structure == "interleaved":
        print(" -> Converting interleaved spin-orbital integrals to AlphaFirst...")
        h0_spin_orbital, U_spin_orbital = transform_integrals_interleaved_to_alphafirst(h0_raw, U_raw, M)
        
    elif spin_structure == "alpha_first":
        print(" -> Integrals are already in AlphaFirst format. No transformation needed.")
        h0_spin_orbital = h0_raw
        U_spin_orbital = U_raw
    
    # 3. Ensure C-contiguous and correct dtype for the C++ backend
    h0 = np.ascontiguousarray(h0_spin_orbital, dtype=np.complex128)
    U = np.ascontiguousarray(U_spin_orbital, dtype=np.complex128)
    
    return h0, U, M

def calculate_bath_filling(h0: np.ndarray, M_imp: int, zero_threshold: float = 1e-2) -> int:
    """
    Estimates the number of electrons in the non-interacting bath orbitals.

    This function assumes a spin-orbital basis where the first M_imp 
    and the M -> M+M_imp orbitals belong to the impurity, and the rest belong to the bath. 
    It counts bath orbitals with single-particle energy below a threshold as fully occupied.

    Args:
        h0 (np.ndarray): The one-body Hamiltonian in the spin-orbital basis.
        M_imp (int): The number of SPATIAL orbitals in the impurity.
        zero_threshold (float): A small energy threshold around zero to handle
                                orbitals exactly at the Fermi level.

    Returns:
        int: The estimated number of electrons in the bath.
    """
    K = h0.shape[0]
    M = K // 2


    num_impurity_spin_orbitals = 2 * M_imp
    num_bath_spatial_orbitals = M - M_imp

    if num_impurity_spin_orbitals >= K:
        print("no bath orbitals found")
        return 0 # No bath orbitals

    bath_filling = 0.0

    bath_indexes_a = [M_imp + i for i in range(num_bath_spatial_orbitals)]
    bath_indexes = bath_indexes_a + [i+M for i in bath_indexes_a]
    
    # Extract the diagonal energies of the bath orbitals
    bath_energies = np.real(np.diag(h0)[bath_indexes])
    
    for energy in bath_energies:
        if energy < -zero_threshold:
            bath_filling += 1.0 # Clearly occupied
        elif abs(energy) < zero_threshold:
            # At the Fermi level, often counted as half-filled,
            # but rounding down is safer for integer electron counts.
            # Your Julia code does this, so we replicate it.
            bath_filling += 0.5
    
    return int(np.floor(bath_filling))import os
import numpy as np
from typing import Union

def dump(
    F: Union[np.ndarray, float, int, complex],
    x: np.ndarray,
    filename: str,
    output_dir: str = "dump",
    float_fmt: str = "%.5f",
    header_comment: str = "#"
) -> None:
    """
    Writes the array `x` and array `F` to a file.

    This is a direct Python port of the provided Julia function. The key
    difference is that the dependent axis in `F` is the FIRST axis (F.shape[0]).

    - `x`: 1D array to be the first column in the output.
    - `F`: Array that can be a scalar, 1D, 2D, or 3D.
    - `filename`: String specifying the path to the output file.
    """
    if not os.path.isdir(output_dir):
        os.makedirs(output_dir)
    full_path = os.path.join(output_dir, filename)

    # --- Prepare data based on F's dimensions ---
    header = ""
    F_processed = None

    if not isinstance(F, np.ndarray):  # Scalar case
        if not np.isscalar(F):
             raise TypeError("F must be a scalar or a numpy array.")
        # Create a column vector by repeating the scalar F
        F_processed = np.full((len(x), 1), F)
    else:
        nd = F.ndim
        # Python convention: first dimension must match x
        if F.shape[0] != len(x):
            raise ValueError(
                f"The first dimension of F (shape: {F.shape}) must match the "
                f"length of x ({len(x)})"
            )

        if nd == 1:
            F_processed = F.reshape(-1, 1)
        elif nd == 2:
            F_processed = F
        elif nd == 3:
            p, q = F.shape[1], F.shape[2]
            F_processed = F.reshape(len(x), p * q)
            # Generate the exact header from the Julia function
            header_lines = [f"{header_comment} Column index map to original (p, q) indices:"]
            counter = 2  # Column 1 is 'x'
            for i in range(p):
                line = " ".join([f"{counter + j:<4d}" for j in range(q)])
                header_lines.append(f"{header_comment} {line}")
                counter += q
            header = "\n".join(header_lines)
        else:
            raise ValueError(f"Unsupported number of dimensions for F: {nd}")

    # Combine x and the processed F into a single array
    # Note: the data array can have a mix of types if F is complex
    data_to_save = np.c_[x, F_processed]

    # --- Manual file writing to replicate Julia's sprintf behavior ---
    with open(full_path, "w") as f:
        if header:
            f.write(header + "\n")

        for row in data_to_save:
            formatted_parts = []
            for item in row:
                # Format floats with the specified format string,
                # otherwise, convert to a standard string (handles complex numbers).
                if isinstance(item, (float, np.floating)):
                    formatted_parts.append(format(item, float_fmt.lstrip('%')))
                else:
                    formatted_parts.append(str(item))
            f.write(" ".join(formatted_parts) + "\n")

    print(f"Data saved to '{full_path}'")# mf.py
import numpy as np
from . import symmetries

def mfscf_(h0_0, U_0, Ne, maxiter=100):
    """
    Mean-field self-consistent field (MF-SCF) loop with simple linear mixing,
    in a basis where spins are BLOCKED (↑ then ↓):
        h0_0[:M,:M]   = spin-↑ block
        h0_0[M:,M:]   = spin-↓ block

    Args:
        h0_0 : (NF, NF) ndarray (complex or real)
            One-particle Hamiltonian in spin-block basis.
        U_0  : (NF, NF, NF, NF) ndarray (real or complex)
            Two-body interaction tensor U[i, j, k, l].
        Ne   : int
            Target total particle number.
        maxiter : int
            Maximum SCF iterations.

    Returns:
        hmf : (M, M) ndarray
            Mean-field spin-↑ block Hamiltonian (the one diagonalized).
        es  : (2M,) ndarray (complex)
            Spin-doubled eigenvalues (degenerate pairs).
        Vs  : (2M, 2M) ndarray (complex)
            Spin-doubled eigenvectors (columns).
        rho : (2M, 2M) ndarray (complex)
            Final density matrix in the full (↑⊕↓) basis.

    Notes:
        We diagonalize only the ↑ block (assuming spin symmetry at start)
        and then duplicate to build the full (↑,↓) structure. The MF potential
        is built on the full NF×NF space.
    """
    NF = h0_0.shape[0]
    M = NF // 2


    # Spin-up block (top-left M×M)
    h0_up = h0_0[:M, :M]

    print("max U :")
    print(np.max(U_0))

    print("starting from ρ(h0) in spin-up block")
    es_up, Vs_up = solve_h0(h0_up)
    es, Vs = double_es_Vs_blocked(es_up, Vs_up)  # build (↑,↓) structure with contiguous blocks
    print(f"iter 0, E = {np.real(es[:Ne]).sum()}")#, es = {es}")
    rho = get_rho(es, Vs, Ne)

    print(f"Ne = {Ne}")
    print(f"tr rho = {np.trace(rho)}")

    alpha = 0.2
    print(f"mixing parameter: α = {alpha}")

    hmf = None
    Vmf = None
    E0 = 1_000.0
    threshold = 1e-6

    # Report sparsity info (optional)
    nz_count = int(np.count_nonzero(U_0))
    print(f"number of non-zero U elements : {nz_count}")

    DE = -1.0
    print(f"{'Iter':>4s} {'E_total':>12s} {'EC':>12s} {'ΔE[n-1]':>15s}")# {'es[1:Ne]':>20s}

    it = 0
    for it in range(1, maxiter + 1):
        # Vectorized mean-field build on the FULL space
        Vmf, ec = get_mean_field(U_0, rho, use_einsum=True)

        # Work in spin-up block for diagonalization
        hmf = h0_up + Vmf[:M, :M]

        es_up, Vs_up = solve_h0(hmf)
        E = 2 * np.real(es[:Ne//2]).sum()
        es, Vs = double_es_Vs_blocked(es_up, Vs_up)
        

        if it % 10 == 0:
            #es_occ = np.real(es[:Ne])
            #es_occ_str = "[" + ", ".join(f"{x:.3f}" for x in es_occ) + "]"
            print(f"{it:4d} {np.real(E + ec):12.8f} {np.real(ec):12.8f} {DE:15.4e}") #{es_occ_str:>20s}

        DE = abs(E - E0)
        if DE < threshold:
            print(f"converged in {it} iterations")
            break
        else:
            E0 = E

        rho_new = get_rho(es, Vs, Ne)
        rho = alpha * rho_new + (1.0 - alpha) * rho

    if it == maxiter:
        print(f"NOT CONVERGED IN {maxiter} ITERATIONS")


    #print(f"HF energies : {es}")
    print(f"tr rho = {np.trace(rho)}")
    return hmf, es, Vs, rho


def get_rho(es, Vs, Ne, beta=1e3):
    """
    rho = sum_n f(ε_n; μ,β) |v_n><v_n|
    μ via bisection so that sum_n f(ε_n) = Ne.
    """
    es = np.real(np.asarray(es))
    M = Vs.shape[0]

    def total_occ(mu):
        x = beta * (es - mu)
        x = np.clip(x, -700, 700)
        return (1.0 / (1.0 + np.exp(x))).sum()

    lo = es.min() - 10.0
    hi = es.max() + 10.0
    mu = _bisection(lambda m: total_occ(m) - Ne, lo, hi, tol=1e-12, maxiter=200)

    x = beta * (es - mu)
    x = np.clip(x, -700, 700)
    f = 1.0 / (1.0 + np.exp(x))
    rho = (Vs * f[np.newaxis, :]) @ Vs.conj().T
    return rho


def solve_h0(h0):
    """
    Hermitian eigenproblem for h0.
    Returns real-sorted eigenvalues and eigenvectors (columns).
    """
    es, Vs = np.linalg.eigh(h0)
    return np.real(es), Vs


def double_es_Vs_blocked(es_up, Vs_up):
    """
    Spin-doubling for BLOCKED basis with BLOCK-DIAGONAL rotation:
      rows 0..M-1  = ↑, rows M..2M-1 = ↓
      columns 0..M-1   are ↑ orbitals
      columns M..2M-1  are ↓ orbitals (identical rotation)

    Returns:
        es_ : (2M,)
        Vs_ : (2M,2M)
    """
    M = len(es_up)
    # concatenate eigenvalues: [all spin-up, then all spin-down]
    es_ = np.zeros(2 * M, dtype=np.complex128)
    es_[:M] = es_up
    es_[M:] = es_up

    Vs_ = np.zeros((2 * M, 2 * M), dtype=np.complex128)
    # block-diagonal: diag(Vs_up, Vs_up)
    Vs_[:M, :M] = Vs_up          # spin-up block columns
    Vs_[M:, M:] = Vs_up          # spin-down block columns
    return es_, Vs_


def get_mean_field(U, rho, use_einsum=True, nz=None):
    
    # Coulomb term with U_ikjl
    J = np.einsum('ijkl,jl->ik', U, rho, optimize=True)
    # Exchange term with U_iljk
    K = np.einsum('ijlk,jl->ik', U, rho, optimize=True)
    
    V = J - K
    
    EC = -0.5 * np.trace(rho @ V)
    return V, float(np.real(EC))

def _bisection(f, a, b, tol=1e-12, maxiter=200):
    """
    Simple bisection for root of f on [a,b] with sign change (or expanded bracket).
    """
    fa = f(a)
    fb = f(b)
    if fa == 0.0:
        return a
    if fb == 0.0:
        return b
    if fa * fb > 0:
        for scale in [2, 4, 8, 16]:
            aa = a - scale * (b - a)
            bb = b + scale * (b - a)
            fa = f(aa)
            fb = f(bb)
            if fa * fb <= 0:
                a, b = aa, bb
                break
        else:
            return 0.5 * (a + b)

    for _ in range(maxiter):
        m = 0.5 * (a + b)
        fm = f(m)
        if abs(b - a) < tol or fm == 0.0:
            return m
        if np.sign(fa) * np.sign(fm) <= 0:
            b, fb = m, fm
        else:
            a, fa = m, fm
    return 0.5 * (a + b)


# -------------------------------------------------

def _reorder_to_spin_blocks(es_sorted, Vs_sorted, M):
    """
    Reorders globally sorted eigenvalues and eigenvectors back into a
    spin-blocked (AlphaFirst) convention. This is necessary when degenerate
    eigenvalues (like in RHF) cause sorting to interleave spin channels.

    Args:
        es_sorted (np.ndarray): Globally sorted eigenvalues.
        Vs_sorted (np.ndarray): Corresponding eigenvectors (columns).
        M (int): Number of spatial orbitals (size of one spin block).

    Returns:
        es_reordered (np.ndarray): Eigenvalues in [alpha..., beta...] order.
        Vs_reordered (np.ndarray): Eigenvectors in the same spin-blocked order.
    """
    NF = 2 * M
    alpha_vectors = []
    beta_vectors = []
    alpha_energies = []
    beta_energies = []

    # Classify each MO as alpha or beta
    for i in range(NF):
        vec = Vs_sorted[:, i]
        # An MO is alpha if its weight is predominantly in the first M components
        is_alpha = np.sum(np.abs(vec[:M])**2) > 0.5
        if is_alpha:
            alpha_vectors.append(vec)
            alpha_energies.append(es_sorted[i])
        else:
            beta_vectors.append(vec)
            beta_energies.append(es_sorted[i])
            
    # Reassemble into the desired block structure
    es_reordered = np.array(alpha_energies + beta_energies)
    Vs_reordered = np.zeros_like(Vs_sorted)
    
    if alpha_vectors:
        Vs_reordered[:, :M] = np.column_stack(alpha_vectors)
    if beta_vectors:
        Vs_reordered[:, M:] = np.column_stack(beta_vectors)
        
    return es_reordered, Vs_reordered

def _solve_h_symmetric(h0: np.ndarray):
    """
    (This function is correct as it was, the problem is handled after its use)
    Diagonalizes a hermitian matrix by exploiting its block-diagonal symmetry.
    Returns globally sorted eigenvalues and eigenvectors.
    """
    sym_dict = symmetries.analyze_symmetries(h0)
    blocks = sym_dict['blocks']
    identical_groups = sym_dict['identical_groups']

    unique_Vs_blocks, unique_es_blocks = {}, {}
    for group in identical_groups:
        leader_idx = group[0]
        leader_block_indices = blocks[leader_idx]
        h_block = h0[np.ix_(leader_block_indices, leader_block_indices)]
        es_block, Vs_block = np.linalg.eigh(h_block)
        unique_es_blocks[leader_idx] = es_block
        unique_Vs_blocks[leader_idx] = Vs_block
        
    Vs = symmetries.assemble_symmetric_hamiltonian(sym_dict, unique_matrices=unique_Vs_blocks)

    all_es = []
    for i in range(len(blocks)):
        found_leader = -1
        for group in identical_groups:
            if i in group:
                found_leader = group[0]
                break
        all_es.extend(unique_es_blocks[found_leader])
    all_es = np.array(all_es)

    sort_indices = np.argsort(np.real(all_es))
    es_sorted = all_es[sort_indices]
    Vs_sorted = Vs[:, sort_indices]
    
    return np.real(es_sorted), Vs_sorted, sym_dict


def mfscf(h0_0, U_0, Ne, maxiter=100, alpha=0.2, threshold=1e-8):
    """
    Symmetry-aware mean-field self-consistent field (MF-SCF) loop.
    This version now returns eigenvectors and eigenvalues in a spin-blocked
    (AlphaFirst) convention, even when degeneracies are present.
    """
    NF = h0_0.shape[0]
    M = NF // 2

    print("--- Initializing SCF from h0 ---")
    es, Vs, sym_dict = _solve_h_symmetric(h0_0)
    print(f"Symmetry analysis found {len(sym_dict['blocks'])} blocks.")
    print(f"Found {len(sym_dict['identical_groups'])} unique groups of blocks.")
    
    rho = get_rho(es, Vs, Ne)
    # The rest of the initial prints...
    print(f"iter 0, Tr(rho*h0) = {np.real(np.trace(rho @ h0_0)):.8f}")
    print(f"Ne = {Ne}, initial tr(rho) = {np.trace(rho):.8f}")
    print(f"mixing parameter: α = {alpha}")

    hmf, E0_total = None, 1_000.0
    
    nz_count = int(np.count_nonzero(U_0))
    print(f"\nNumber of non-zero U elements: {nz_count}")
    print(f"{'Iter':>4s} {'E_total':>15s} {'E_corr':>15s} {'ΔE_total':>15s}")
    
    it = 0
    for it in range(1, maxiter + 1):
        Vmf, ec = get_mean_field(U_0, rho)
        hmf = h0_0 + Vmf
        es, Vs, _ = _solve_h_symmetric(hmf) # es and Vs are globally sorted here

        E_total = 0.5 * np.real(np.trace(rho @ (h0_0+hmf)))
        DE = abs(E_total - E0_total)
        
        if it % 10 == 0 or it == 1:
            print(f"{it:4d} {E_total:15.8f} {np.real(ec):15.8f} {DE:15.4e}")

        if DE < threshold:
            print(f"\nConverged in {it} iterations.")
            break
        
        E0_total = E_total

        rho_new = get_rho(es, Vs, Ne)
        rho = alpha * rho_new + (1.0 - alpha) * rho

    if it == maxiter:
        print(f"\nNOT CONVERGED IN {maxiter} ITERATIONS")

    print(f"\nFinal tr(rho) = {np.trace(rho):.8f}")
    
    # --- FINAL FIX-UP STEP ---
    # Reorder the final results to conform to the spin-blocked convention
    print("Reordering final eigenvectors to spin-blocked convention...")
    es_final, Vs_final = _reorder_to_spin_blocks(es, Vs, M)
    
    # Return the reordered, user-friendly results
    return hmf, es_final, Vs_final, rho


# ops.py
from . import clic_clib as cc
import numpy as np

def one_rdm(wf,M,block=None):
    """ 
    TO DO : currently too expensive. Should check first if occ
    Compute the one-body reduced density matrix given a wavefunction
    Args:
        wf : a wavefunction object
        M  : number of spatial orbitals 
        block: if not None, return the rdm only for the block indexes
    Returns:
        np.ndarray: the 1-rdm
    """

    if block == None : 
        K = 2*M
        block = list(range(K))
    else : 
        K = len(block)

    #wf.normalize()
    rdm = np.zeros((K, K), dtype=np.complex128)
    for (i,ib) in enumerate(block):
        for (j,jb) in enumerate(block):
            # Create the operator term c†_i c_j
            spin_i = cc.Spin.Alpha if ib < M else cc.Spin.Beta
            spin_j = cc.Spin.Alpha if jb < M else cc.Spin.Beta
            orb_i = ib if ib < M else ib - M
            orb_j = jb if jb < M else jb - M
            
            # The operator term is a list containing a single tuple (h_ij = 1.0)
            op_term = [(orb_i, orb_j, spin_i, spin_j, 1.0)]
            
            # Apply the operator c†_i c_j to the ground state
            # This creates the state |Φ⟩ = c†_i c_j |Ψ⟩
            phi_wf = cc.apply_one_body_operator(wf, op_term)
            #phi_wf.normalize()
            
            # The RDM element is <Ψ|Φ>
            rdm[i, j] = wf.dot(phi_wf)

    return rdm


def get_ham(basis,h0,U,method="openmp"):
    """TO ADD : DETECT SPIN FLIPS TERMS"""
    h0 = np.ascontiguousarray(h0, dtype=np.complex128)
    U = np.ascontiguousarray(U, dtype=np.complex128)

    if method == "openmp":
        H = cc.build_hamiltonian_openmp(basis, h0, U)
    else : 
        print("method not implemented yet")
        assert 1==2
    return H 


def get_one_body_terms(h0, M, thr=1e-12):
    """
    The non-zeros (above threshold) elements of the one-body hamiltonian
    Args:
        h0 (np.ndarray): the one-body hamiltonian, A 2D array (matrix).
        M: the number of spatial orbitals.
        thr: optional, a threshold value for the returned elements

    Returns:
        list: A list containing the non zeros elements and the corresponding orbitals
    """
    terms = []
    for i in range(2*M):
        for j in range(2*M):
            if abs(h0[i, j]) > thr:
                spin_i = cc.Spin.Alpha if i < M else cc.Spin.Beta
                spin_j = cc.Spin.Alpha if j < M else cc.Spin.Beta
                orb_i = i if i < M else i - M
                orb_j = j if j < M else j - M
                terms.append((orb_i, orb_j, spin_i, spin_j, complex(h0[i, j])))
    return terms

def get_two_body_terms(U, M, thr=1e-12):
    """
    The non-zeros (above threshold) elements of the two-body hamiltonian
    Args:
        U (np.ndarray): the two-body hamiltonian, A 4D array (tensor).
        M: the number of spatial orbitals.
        thr: optional, a threshold value for the returned elements

    Returns:
        list: A list containing the non zeros elements and the corresponding orbitals
    """
    terms = []
    for i in range(2*M):
        for j in range(2*M):
            for k in range(2*M):
                for l in range(2*M):
                    if abs(U[i, j, k, l]) > thr:
                        spins = [cc.Spin.Alpha if idx < M else cc.Spin.Beta for idx in [i, j, k, l]]
                        orbs = [idx if idx < M else idx - M for idx in [i, j, k, l]]
                        terms.append((orbs[0], orbs[1], orbs[2], orbs[3],
                                      spins[0], spins[1], spins[2], spins[3],
                                      complex(U[i, j, k, l])))
    return terms



def expect_Sz_from_rdm(rdm, M, block):
    # uses the block mapping you built in one_rdm
    val = 0.0
    for i, ib in enumerate(block):
        if ib < M:
            val += 0.5 * rdm[i, i]
        else:
            val -= 0.5 * rdm[i, i]
    return np.real(val)

def apply_Sz(wf, M, block=None):
    if block is None:
        block = list(range(2*M))
    terms = []
    for ib in block:
        spin = cc.Spin.Alpha if ib < M else cc.Spin.Beta
        orb  = ib if ib < M else ib - M
        coeff = 0.5 if ib < M else -0.5
        terms.append((orb, orb, spin, spin, coeff))
    # try batched apply if available
    try:
        return cc.apply_one_body_operator(wf, terms)
    except Exception:
        acc = wf.zero_like()
        for t in terms:
            acc = acc + cc.apply_one_body_operator(wf, [t])
        return acc

def expect_Sz(wf, M, block=None):
    if block is None:
        block = list(range(2*M))
    rdm = one_rdm(wf, M, block)
    return expect_Sz_from_rdm(rdm, M, block)

# prebuild S± term lists once per M
def _terms_Sminus(M):
    # S- = sum_p c†_{pβ} c_{pα}
    return [(p, p, cc.Spin.Beta,  cc.Spin.Alpha, 1.0) for p in range(M)]

def _terms_Splus(M):
    # S+ = sum_p c†_{pα} c_{pβ}
    return [(p, p, cc.Spin.Alpha, cc.Spin.Beta,  1.0) for p in range(M)]

def _apply_sum_terms(wf, terms):
    # try one batched call; fallback to accumulation
    try:
        return cc.apply_one_body_operator(wf, terms)
    except Exception:
        acc = wf.zero_like()
        for t in terms:
            acc = acc + cc.apply_one_body_operator(wf, [t])
        return acc

def expect_Splus_Sminus(wf, M):
    # ⟨Ψ| S+ S- |Ψ⟩ = ⟨Ψ| S+ (S- |Ψ⟩)⟩
    psi1 = _apply_sum_terms(wf, _terms_Sminus(M))
    psi2 = _apply_sum_terms(psi1, _terms_Splus(M))
    return np.real(wf.dot(psi2))

def expect_Sminus_Splus(wf, M):
    psi1 = _apply_sum_terms(wf, _terms_Splus(M))
    psi2 = _apply_sum_terms(psi1, _terms_Sminus(M))
    return np.real(wf.dot(psi2))

def expect_S2(wf, M, block=None):
    # ⟨S_z⟩ and ⟨S_z^2⟩
    if block is None:
        block = list(range(2*M))
    Sz = expect_Sz(wf, M, block)
    phi = apply_Sz(wf, M, block)
    Sz2 = np.real(phi.dot(phi))
    # ladder pieces
    SpSm = expect_Splus_Sminus(wf, M)
    SmSp = expect_Sminus_Splus(wf, M)
    S2 = Sz2 + 0.5*(SpSm + SmSp)
    return S2, Sz



import numpy as np
import matplotlib.pyplot as plt

def plot_spectral_function(ws, A_w, impurity_indices, title, filename=None):
    """
    Plots the impurity spectral function A(w) and saves it to a file.
    """
    print(f"impurity_indices = {impurity_indices}")
    if len(np.shape(A_w)) == 3:
        dos = np.sum(A_w[:, impurity_indices, impurity_indices], axis=1).real
    elif len(np.shape(A_w)) == 2:
        dos = np.sum(A_w[:, impurity_indices], axis=1).real
    plt.figure(figsize=(8, 5))
    plt.plot(ws, dos, label="Total Impurity DOS")
    plt.title(title)
    plt.xlabel("Frequency (ω)")
    plt.ylabel("A(ω) (arb. units)")
    plt.grid(True)
    plt.legend()
    
    if filename:
        plt.savefig(filename, dpi=300)
        print(f"Plot saved to '{filename}'")
    else:
        plt.show()

    plt.close()# analysis.py (excerpt)
import numpy as np
from scipy.sparse import lil_matrix
from . import results, ops
from .api import Model

def _get_1p_Sz_matrix(M):
    sz_diag = np.concatenate([np.full(M, 0.5), np.full(M, -0.5)])
    return np.diag(sz_diag)

class StateAnalyzer:
    def __init__(self, result_obj, model: Model):
        if isinstance(result_obj, results.NelecLowEnergySubspace):
            res_dict = {result_obj.Nelec: result_obj}
            self.thermal_state = results.ThermalGroundState(res_dict, temperature=1e-6)
        elif isinstance(result_obj, results.ThermalGroundState):
            self.thermal_state = result_obj
        else:
            raise TypeError("result_obj must be NelecLowEnergySubspace or ThermalGroundState")
        self.model = model
        self._1p_op_cache = {}

    def _get_1p_operators(self):
        if "Sz" in self._1p_op_cache:
            return self._1p_op_cache
        num_imp_spatial = len(self.model.imp_indices)
        Sz_op = _get_1p_Sz_matrix(num_imp_spatial)
        self._1p_op_cache = {"Sz": Sz_op}
        return self._1p_op_cache

    def _calculate_single_state_stats(self, wf, nelec):
        stats = {}

        # many body expectations without building operators
        S2, Sz_full = ops.expect_S2(wf, self.model.M)

        # S is only meaningful if eigenstate; still report the derived value
        S = 0.5 * (np.sqrt(1.0 + 4.0 * np.real(S2)) - 1.0)
        stats["S2"] = np.real(S2)
        stats["S"]  = np.real(S)

        if self.model.is_impurity_model:
            imp_spinfull = self.model.imp_indices + [i + self.model.M for i in self.model.imp_indices]
            rdm_imp = ops.one_rdm(wf, self.model.M, block=imp_spinfull)
            stats["occ"] = float(np.sum(np.real(np.diag(rdm_imp))))
            stats["rdm"] = rdm_imp

            op_1p = self._get_1p_operators()
            exp_Sz_imp = np.trace(op_1p["Sz"] @ rdm_imp)
            stats["Sz"] = float(np.real(exp_Sz_imp))
        else:
            stats["occ"] = self.model.Nelec
            stats["rdm"] = None
            # use the full-system Sz from ops.expect_S2 return
            stats["Sz"] = float(np.real(Sz_full))

        return stats

    def print_analysis(self):
        all_states = self.thermal_state._all_states
        weights = self.thermal_state.boltzmann_weights
        if not all_states:
            print("No states to analyze.")
            return

        _, gs_energy, _ = self.thermal_state.find_absolute_ground_state()

        print("-"*50)
        print("RETAINED STATES:")
        print("-"*50)
        print(f"GS: e0 = {gs_energy:.12f}")

        all_stats = []
        avg_rdm_imp = 0
        for i, (energy, nelec, wf) in enumerate(all_states):
            stats = self._calculate_single_state_stats(wf, nelec)
            if self.model.is_impurity_model:
                avg_rdm_imp += weights[i] * stats["rdm"]
            all_stats.append(stats)

            print(f"e-e0: {energy - gs_energy:10.8f}, "
                  f"ne: {nelec}, "
                  f"weight: {weights[i]:10.4f}, "
                  f"occ: {stats['occ']:10.4f}, "
                  f"S2: {stats['S2']:10.4f}, "
                  f"S: {stats['S']:10.4f}, "
                  f"Sz: {stats['Sz']:10.4f}")

        if self.model.is_impurity_model:
            print("Saving thermally-averaged impurity density matrix...")
            np.savetxt("real-imp-dens.dat", np.real(avg_rdm_imp), fmt="% 8.5f")
            print("-> Saved 'real-imp-dens.dat'")
            np.savetxt("imag-imp-dens.dat", np.imag(avg_rdm_imp), fmt="% 8.5f")
            print("-> Saved 'imag-imp-dens.dat'")

        if len(all_states) > 1:
            avg_occ = float(np.sum(weights * [s["occ"] for s in all_stats]))
            avg_S2  = float(np.sum(weights * [s["S2"] for s in all_stats]))
            avg_S   = float(np.sum(weights * [s["S"]  for s in all_stats]))
            avg_Sz  = float(np.sum(weights * [s["Sz"] for s in all_stats]))
            print("thermal averages:")
            print(f"<occ> = {avg_occ:.8f}")
            print(f"<S2>  = {avg_S2:.8f}")
            print(f"<S>   = {avg_S:.8f}")
            print(f"<Sz>  = {avg_Sz:.8f}")
        print("-"*50)# clic/results.py
import numpy as np
import h5py
from . import clic_clib as cc # for Wavefunction type hint

# Use TYPE_CHECKING block to import for type hints only, preventing circular imports
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .api import Model


class NelecLowEnergySubspace:
    """
    Holds the results of a CI calculation for a fixed particle number.
    This object contains the computed eigenstates and the basis information
    they are expressed in.
    """
    def __init__(self,
                 M: int,
                 Nelec: int,
                 energies: np.ndarray,
                 wavefunctions: list[cc.Wavefunction],
                 basis: list[cc.SlaterDeterminant],
                 transformation_matrix: np.ndarray | None = None):
        
        self.M = M
        self.Nelec = Nelec
        
        self.energies = np.asarray(energies)
        self.wavefunctions = wavefunctions
        self.basis = basis # The common basis for all wavefunctions in this result
        self.transformation_matrix = transformation_matrix # From original to final basis

    @property
    def ground_state_energy(self) -> float:
        """Convenience property for the lowest energy eigenvalue."""
        return self.energies[0]

    @property
    def ground_state_wavefunction(self) -> cc.Wavefunction:
        """Convenience property for the ground state wavefunction."""
        return self.wavefunctions[0]

    def save(self, target: str | h5py.Group):
        """
        Saves the complete result to a structured HDF5 file or group.
        
        Args:
            target: A filename (str) or an h5py.Group object.
        """
        def _save_to_group(group: h5py.Group):
            # Flatten basis occupation lists for robust HDF5 saving
            alpha_indices_flat = []
            alpha_endpoints = [0]
            for det in self.basis:
                alpha_indices_flat.extend(det.alpha_occupied_indices())
                alpha_endpoints.append(len(alpha_indices_flat))
            
            beta_indices_flat = []
            beta_endpoints = [0]
            for det in self.basis:
                beta_indices_flat.extend(det.beta_occupied_indices())
                beta_endpoints.append(len(beta_indices_flat))

            # === Metadata Group ===
            meta = group.create_group("metadata")
            meta.attrs["M"] = self.M
            meta.attrs["Nelec"] = self.Nelec
            meta.attrs["num_states"] = len(self.wavefunctions)
            meta.attrs["basis_size"] = len(self.basis)
            meta.create_dataset("energies", data=self.energies)
            
            # === Basis Group ===
            basis_gp = group.create_group("basis")
            if self.transformation_matrix is not None:
                basis_gp.create_dataset("transformation_matrix", data=self.transformation_matrix)
            
            basis_gp.create_dataset("alpha_indices_flat", data=np.asarray(alpha_indices_flat, dtype=np.int64))
            basis_gp.create_dataset("alpha_endpoints", data=np.asarray(alpha_endpoints, dtype=np.int64))
            basis_gp.create_dataset("beta_indices_flat", data=np.asarray(beta_indices_flat, dtype=np.int64))
            basis_gp.create_dataset("beta_endpoints", data=np.asarray(beta_endpoints, dtype=np.int64))
            
            # === Wavefunctions Group ===
            wf_gp = group.create_group("wavefunctions")
            for i, wf in enumerate(self.wavefunctions):
                if wf.get_basis() != self.basis:
                    raise RuntimeError(f"Basis mismatch for wavefunction {i} during save.")
                wf_gp.create_dataset(f"state_{i}_coeffs", data=wf.get_amplitudes())

        if isinstance(target, str):
            print(f"Saving Nelec={self.Nelec} subspace to file '{target}'...")
            with h5py.File(target, 'w') as f:
                _save_to_group(f)
        else: # Assumes target is an h5py.Group
            print(f"Saving Nelec={self.Nelec} subspace to HDF5 group '{target.name}'...")
            _save_to_group(target)
        
        print("Save complete.")

    @classmethod
    def load(cls, source: str | h5py.Group):
        """
        Loads a complete result from an HDF5 file or group.
        
        Args:
            source: A filename (str) or an h5py.Group object.
        """
        def _load_from_group(group: h5py.Group):
            # Load Metadata
            meta = group["metadata"]
            M = int(meta.attrs["M"])
            Nelec = int(meta.attrs["Nelec"])
            num_states = int(meta.attrs["num_states"])
            basis_size = int(meta.attrs["basis_size"])
            energies = meta["energies"][:]
            
            # Reconstruct Basis
            basis_gp = group["basis"]
            transformation_matrix = basis_gp["transformation_matrix"][:] if "transformation_matrix" in basis_gp else None
            
            alpha_indices_flat = basis_gp["alpha_indices_flat"][:]
            alpha_endpoints = basis_gp["alpha_endpoints"][:]
            beta_indices_flat = basis_gp["beta_indices_flat"][:]
            beta_endpoints = basis_gp["beta_endpoints"][:]

            alpha_list = [alpha_indices_flat[alpha_endpoints[i]:alpha_endpoints[i+1]] for i in range(basis_size)]
            beta_list = [beta_indices_flat[beta_endpoints[i]:beta_endpoints[i+1]] for i in range(basis_size)]
            
            basis = [cc.SlaterDeterminant(M, a, b) for a, b in zip(alpha_list, beta_list)]

            # Reconstruct Wavefunctions
            wf_gp = group["wavefunctions"]
            wavefunctions = []
            for i in range(num_states):
                coeffs = wf_gp[f"state_{i}_coeffs"][:]
                wf = cc.Wavefunction(M, basis, coeffs)
                wavefunctions.append(wf)
            
            return cls(M=M, Nelec=Nelec, energies=energies, wavefunctions=wavefunctions,
                       basis=basis, transformation_matrix=transformation_matrix)

        if isinstance(source, str):
            print(f"Loading eigenstate results from file '{source}'...")
            with h5py.File(source, 'r') as f:
                instance = _load_from_group(f)
        else: # Assumes source is an h5py.Group
            print(f"Loading eigenstate results from HDF5 group '{source.name}'...")
            instance = _load_from_group(source)
            
        print("Load complete.")
        return instance

# We define the Boltzmann constant in eV/K.
K_B_IN_EV_PER_K = 8.617333262e-5 # eV/K
k_B_IN_RY_PER_K = 0.0000063336   # Ry/K 

class ThermalGroundState:
    """
    Holds and manages a collection of low-energy eigenstates from different
    particle number (Nelec) sectors to describe a system at a given temperature.

    It is assumed that the chemical potential has already been absorbed into the
    one-body part of the Hamiltonian used to generate these eigenstates.
    """
    def __init__(self,
                 results_by_nelec: dict[int, 'NelecLowEnergySubspace'],
                 base_model: 'Model',
                 temperature: float = 5.0):
        
        if not isinstance(results_by_nelec, dict):
            raise TypeError("`results_by_nelec` must be a dictionary.")

        # --- Store base model information ---
        self.base_h0 = base_model.h0
        self.base_U = base_model.U
        self.M = base_model.M
        self.is_impurity_model = base_model.is_impurity_model
        self.imp_indices = base_model.imp_indices
        
        self.results_by_nelec = results_by_nelec
        self._temperature = temperature
        
        self._all_states: list[tuple[float, int, cc.Wavefunction]] = []
        for nelec, result in self.results_by_nelec.items():
            for i, energy in enumerate(result.energies):
                self._all_states.append((energy, nelec, result.wavefunctions[i]))

        self._all_states.sort(key=lambda s: s[0])
        self.boltzmann_weights: np.ndarray | None = None
        self.partition_function: float | None = None
        self._recalculate_thermal_properties()

    @property
    def temperature(self) -> float:
        """The temperature of the system in Kelvin."""
        return self._temperature

    @temperature.setter
    def temperature(self, value: float):
        """Sets the temperature and recalculates thermal properties."""
        if value <= 0:
            raise ValueError("Temperature must be positive.")
        self._temperature = value
        self._recalculate_thermal_properties()
        
    def _recalculate_thermal_properties(self):
        """
        Internal method to update Boltzmann weights and partition function
        whenever temperature changes.
        """
        if not self._all_states:
            self.boltzmann_weights = np.array([])
            self.partition_function = 0.0
            return

        # Assumes energies are in eV. Change k_B constant if units differ.
        #beta = 1.0 / (K_B_IN_EV_PER_K * self._temperature)
        beta = 1.0 / (k_B_IN_RY_PER_K * self._temperature)
        
        energies = np.array([s[0] for s in self._all_states])
        
        # Subtract the ground state energy to prevent numerical overflow in exp()
        # This factor cancels out upon normalization.
        ground_state_energy = energies[0] # Since the list is sorted
        unnormalized_weights = np.exp(-beta * (energies - ground_state_energy))
        
        self.partition_function = np.sum(unnormalized_weights)
        self.boltzmann_weights = unnormalized_weights / self.partition_function
        
        print(f"Recalculated thermal properties for T={self.temperature} K.")

    def prune(self, threshold: float = 1e-8):
        """
        Removes states whose Boltzmann weight is below a given threshold.
        This method completely rebuilds the internal state of the object,
        purging all information related to the pruned states.
        """
        if self.boltzmann_weights is None:
            self._recalculate_thermal_properties()

        initial_count = len(self._all_states)
        if initial_count == 0:
            print("No states to prune.")
            return

        # 1. Identify which states to keep
        indices_to_keep = np.where(self.boltzmann_weights >= threshold)[0]
        
        if len(indices_to_keep) == initial_count:
            print(f"No states pruned with threshold {threshold:.1e}.")
            return

        # 2. Keep only the surviving states in the flattened list
        self._all_states = [self._all_states[i] for i in indices_to_keep]
        
        # --- 3. CRUCIAL STEP: Rebuild the results_by_nelec dictionary from scratch ---
        new_results_by_nelec = {}
        
        # Group surviving states by their Nelec
        grouped_states = {}
        for energy, nelec, wf in self._all_states:
            if nelec not in grouped_states:
                grouped_states[nelec] = []
            grouped_states[nelec].append({"energy": energy, "wavefunction": wf})

        # For each group, create a new, minimal NelecLowEnergySubspace object
        for nelec, states_info in grouped_states.items():
            states_info.sort(key=lambda x: x["energy"])
            surviving_wfs = [s["wavefunction"] for s in states_info]
            surviving_energies = [s["energy"] for s in states_info]
            
            # Create a minimal basis just for the surviving wavefunctions in this sector
            new_basis_set = set()
            for wf in surviving_wfs:
                new_basis_set.update(wf.data().keys())
            pruned_basis = sorted(list(new_basis_set))
            
            # Re-express the wavefunctions in this new minimal basis
            new_wavefunctions = []
            det_to_idx = {det: i for i, det in enumerate(pruned_basis)}
            original_M = self.results_by_nelec[nelec].M
            for wf in surviving_wfs:
                new_coeffs = np.zeros(len(pruned_basis), dtype=np.complex128)
                for det, coeff in wf.data().items():
                    new_coeffs[det_to_idx[det]] = coeff
                new_wavefunctions.append(cc.Wavefunction(original_M, pruned_basis, new_coeffs))
            
            # Get other metadata from the original object (this is the only time we need it)
            original_transform = self.results_by_nelec[nelec].transformation_matrix

            # Create the new, clean result object for this Nelec sector
            new_results_by_nelec[nelec] = NelecLowEnergySubspace(
                M=original_M,
                Nelec=nelec,
                energies=np.array(surviving_energies),
                wavefunctions=new_wavefunctions,
                basis=pruned_basis,
                transformation_matrix=original_transform
            )

        # 4. Replace the old, complete dictionary with the new, pruned one
        self.results_by_nelec = new_results_by_nelec
        
        # 5. Finally, recalculate the Boltzmann weights for the pruned set
        self._recalculate_thermal_properties()
        final_count = len(self._all_states)
        print(f"Pruned {initial_count - final_count} states. {final_count} states remaining.")

    def find_absolute_ground_state(self) -> tuple[int, float, cc.Wavefunction]:
        """
        Finds the state with the lowest energy across all calculated Nelec sectors.

        Returns:
            A tuple of (Nelec, ground_state_energy, ground_state_wavefunction).
        """
        if not self._all_states:
            raise ValueError("No states are stored.")

        # Since _all_states is sorted by energy, the ground state is the first one.
        gs_energy, gs_nelec, gs_wf = self._all_states[0]
        return gs_nelec, gs_energy, gs_wf

    def save(self, filename: str):
        """Saves all contained results and model info into a single HDF5 file."""
        print(f"Saving thermal state data to '{filename}'...")
        with h5py.File(filename, 'w') as f:
            f.attrs["file_type"] = "ThermalGroundState"
            f.attrs["temperature"] = self.temperature
            
            # --- Save the base model context ---
            f.attrs["M"] = self.M
            f.attrs["is_impurity_model"] = self.is_impurity_model
            if self.is_impurity_model:
                f.attrs["imp_indices"] = self.imp_indices
            f.create_dataset("base_h0", data=self.base_h0)
            f.create_dataset("base_U", data=self.base_U)

            for nelec, result in self.results_by_nelec.items():
                nelec_group = f.create_group(f"nelec_{nelec}")
                print(f"Saving Nelec={nelec} subspace to HDF5 group '{nelec_group.name}'...")
                result.save(nelec_group)
        print("Save complete.")


    @classmethod
    def load(cls, filename: str):
        """Loads a thermal state result from a single HDF5 file."""
        print(f"Loading thermal state data from '{filename}'...")
        results = {}
        with h5py.File(filename, 'r') as f:
            if f.attrs.get("file_type") != "ThermalGroundState":
                 print(f"Warning: File '{filename}' may not be a valid ThermalGroundState file.")
            
            temp = f.attrs.get("temperature", 300.0)
            
            # Import Model locally to avoid circular dependency at module level
            from .api import Model

            # --- Load the base model context ---
            M = int(f.attrs["M"])
            is_imp = bool(f.attrs["is_impurity_model"])
            imp_indices = list(f.attrs.get("imp_indices", []))
            base_h0 = f["base_h0"][:]
            base_U = f["base_U"][:]
            
            # Reconstruct the model object. Nelec is just a placeholder here.
            loaded_model = Model(h0=base_h0, U=base_U, M_spatial=M, Nelec=-1)
            loaded_model.is_impurity_model = is_imp
            loaded_model.imp_indices = imp_indices

            for key in f.keys():
                if key.startswith("nelec_"):
                    nelec = int(key.split("_")[1])
                    nelec_group = f[key]
                    print(f"Loading Nelec={nelec} subspace from HDF5 group '{nelec_group.name}'...")
                    results[nelec] = NelecLowEnergySubspace.load(nelec_group)
        
        print("Load complete.")
        return cls(results, base_model=loaded_model, temperature=temp)
# sci.py
from . import clic_clib as cc
from itertools import combinations
import numpy as np
from . import basis_Np,hamiltonians,ops,results,basis_1p
from scipy.sparse.linalg import eigsh 
from numpy.linalg import eigh,eig


def selective_ci(
    h0, U, C,
    M, Nelec,
    seed,
    generator,
    selector,
    num_roots=1,
    one_bh=None,
    two_bh=None,
    max_iter=5,
    conv_tol=1e-6,
    prune_thr=1e-7,
    Nmul = None,
    min_size=512,
    max_size=5e4,
    verbose=True,
):
    """
    Generic selective-CI driver.

    Parameters
    ----------
    h0 : (K,K) array_like
        One-particle Hamiltonian (spin-orbital or spatial; your helpers decide).
    U  : (K,K,K,K) array_like
        Two-particle Hamiltonian (spin-orbital convention matching `get_*_terms`).
    C : (K,K) array_like 
        Transformation matrix (we want to keep track of it)
    M  : int
        Number of spatial orbitals.
    Nelec : int
        Total number of electrons.
    seed : list
        The inital basis
    generator : callable
        Expansion proposal function. Must have signature:
            generator(wf, ewf, one_body_terms, two_body_terms, K, h0, U, thr=...)
        and return an *iterable of SlaterDeterminant* to add.
    num_roots : int 
        Number of eigenvectors computed and return at the FINAL iteration
    one_bh : list
        one body non zero terms of the hamiltonians, computed if not given 
    two_bh : list
        wo body ... 
    max_iter : int
        Maximum number of CI selection iterations.
    conv_tol : float
        Convergence threshold on energy change |E_new - E_old|.
    prune_thr : float
        Wavefunction prune threshold passed to `generator`.  
    Nmul : float 
        If positive, the size of the retained elements in generated basis is Nmul * len(current basis)
        If None, we keep the full generated basis.
    min_size : Int -> to do  
    max_size : Int -> to do 
    verbose : bool
        Print iteration logs.

    Returns
    -------
    result : dict
        {
          "energy": E0,
          "wavefunction": psi0,
          "basis": basis0,
          "energies": energies_per_iter,
          "sizes": sizes_per_iter,
        }

    Note: called with generator=cipsi_one_iter, max_iter=5, Nmul=None, this is CISD
    """



    basis0=seed

    # Initial Hamiltonian and ground state
    H = ops.get_ham(basis0, h0, U)
    # For small bases, a dense eig can be faster / safer; otherwise eigsh.
    dim0 = H.shape[0]
    if dim0 <= 256:
        from numpy.linalg import eigh
        evals, evecs = eigh(H.toarray())
        e0 = float(evals[0])
        psi0 = cc.Wavefunction(M, basis0, evecs[:, 0])
    else:
        evals, evecs = eigsh(H, k=1, which='SA')
        e0 = float(evals[0])
        psi0 = cc.Wavefunction(M, basis0, evecs[:, 0])

    if verbose:
        print(f"[init] dim={len(basis0)}  E0={e0:.12f}")

    energies = [e0]
    sizes = [len(basis0)]

    if generator == hamiltonian_generator:
        # Precompute operator terms once
        if one_bh == None:
            one_bh = ops.get_one_body_terms(h0, M)
        if two_bh == None:
            two_bh = ops.get_two_body_terms(U, M)

    def get_roots(H,nroots,dim):
        if dim <= 64:
            evals, evecs = eigh(H.toarray())
        else:
            evals, evecs = eigsh(H, k=nroots, which='SA')
        indsort = np.argsort(np.real(evals))
        evals=evals[indsort]
        evecs=evecs[:,indsort]
        return evals[:nroots], evecs[:, :nroots]



    # Main selection loop
    for it in range(max_iter):
        # Propose new determinants using the provided generator

        inds,blocks = basis_Np.partition_by_Sz(basis0)
        print(f"blocks = {blocks}")

        current_size = len(basis0)

        gen_basis,hwf = generator(psi0,one_bh,two_bh,thr=prune_thr,return_hwf=True)
        selected_basis = selector(hwf,e0,gen_basis,2*M,h0,U)

        # If Nmul = 1.0, at each iteration we double the basis size 
        #if Nmul != None : 
        #    nkeep = Nmul * lenb 
        #    nkeep = int(min(nkeep, len(selected_basis)))
        #    selected_basis = selected_basis[:nkeep]
        # --- Determine how many new determinants to keep based on size constraints ---
        num_candidates = len(selected_basis)

        # 1. Calculate target number of new states from Nmul
        if Nmul is not None:
            n_add_nmul = int(Nmul * current_size)
        else:
            # If Nmul is None, we are unconstrained by it, so consider all candidates
            n_add_nmul = num_candidates

        # 2. Calculate number of new states needed to reach min_size
        n_add_min = max(0, min_size - current_size)
        # 3. Take the maximum of the two suggestions
        n_to_add = max(n_add_nmul, n_add_min)

        # 4. Cap by the number of available candidates
        n_to_add = min(n_to_add, num_candidates)
        
        # 5. Cap to not exceed max_size
        n_to_add = min(n_to_add, max_size - current_size)

        n_to_add = int(max(0, n_to_add)) # Ensure it's not negative

        # Truncate the selected basis to the final number of states to add
        final_selected = selected_basis[:n_to_add]
        # Merge and sort the basis
        new_basis = set(basis0) | set(final_selected)

        if len(new_basis) == len(basis0):
            if verbose:
                print(f"[iter {it}] no new determinants proposed; stopping.")
            break

        basis0 = sorted(list(new_basis))


        

        # Rebuild H and solve ground state
        H = ops.get_ham(basis0, h0, U)
        dim = H.shape[0]
        
        evals, evecs = get_roots(H, num_roots, dim)
        e_new = float(evals[0])
        psi0 = cc.Wavefunction(M, basis0, evecs[:, 0])

        dE = abs(e_new - energies[-1])
        energies.append(e_new)
        sizes.append(dim)

        if verbose:
            Es_str = " ".join(f"{ev:.12f}" for ev in evals[:num_roots])
            print(f"[iter {it}] dim={dim:>6}  Es=[{Es_str}]  |dE0|={dE:.3e}")

        if dE < conv_tol:
            if verbose:
                print(f"[conv] reached |dE| < {conv_tol}")
            break


    
    if num_roots > len(basis0):
        print("num_roots > length(basis)")
        num_roots = len(basis0)

    evals, evecs = get_roots(H, num_roots, len(basis0))
    psis = [cc.Wavefunction(M, basis0, evecs[:, i], keep_zeros=True) for i in range(num_roots)]


    sci_res = results.NelecLowEnergySubspace(M=M,Nelec=Nelec,
        energies=evals,
        wavefunctions=psis,
        basis=basis0,
        transformation_matrix=C
    )

    return sci_res


def do_fci(h0,U,M,Nelec,num_roots=1,Sz=0,verbose=True):

    basis = basis_Np.get_fci_basis(M, Nelec)
    #inds, blocks = partition_by_Sz(basis)    # lists of indices + Sz values
    basis, idxs0 = basis_Np.subbasis_by_Sz(basis, Sz)  # S_z = 0 sector
    print(f"fci basis size = {len(basis)}")

    H_sparse = ops.get_ham(basis,h0,U,method="openmp")
    eigvals, eigvecs = eigsh(H_sparse, k=num_roots, which='SA')
    indsort = np.argsort(np.real(eigvals))
    eigvals=eigvals[indsort]
    eigvecs=eigvecs[:,indsort]
    if verbose:
        Es_str = " ".join(f"{ev:.12f}" for ev in eigvals[:num_roots])
        print(f"Es=[{Es_str}]")
    psis = [cc.Wavefunction(M, basis, eigvecs[:,i]) for i in range(num_roots)]

    fci_res = results.NelecLowEnergySubspace(M=M,Nelec=Nelec,
        energies=eigvals,
        wavefunctions=psis,
        basis=basis,
        transformation_matrix=None
    )
    return fci_res


# -----------
# Generators
# -----------

def hamiltonian_generator(wf,one_body_terms,two_body_terms,thr=1e-7,return_hwf=True):
    r"""
    The basis is expanded by acting on a state with the hamiltonian

    Args : 
        wf: the input wavefunction :math:`|\psi\rangle`, a Wavefunction object 
        one_body_terms: the one_body part of the hamiltonian 
        two_body_terms: ..
        h0: the one particle hamiltonian 
        U : the two particle hamitlonian 
        thr : Basis elements with absolute coefficient below threshold are pruned before expansion
        return_hwf: if True, return the new wavefunction :math:`H|\psi\rangle` as well

    Returns: 
        diffbasis: the unique new basis terms 
        hwf: optional, the new wavefunction

    """
    #wf.prune(thr)

    if return_hwf:
        hwf = cc.apply_one_body_operator(wf,one_body_terms) + cc.apply_two_body_operator(wf,two_body_terms)
        hwf.prune(thr)
        basis_hwf = hwf.get_basis()
        diffbasis = list(set(basis_hwf) - set(wf.get_basis()))

        return diffbasis,hwf 
    
    else:
        print("hamiltonian generator with return_hwf not implemented yet")


# -----------
# Selectors
# -----------

def cipsi_one_iter(hwf,ewf,diffbasis,K, h0,U):
    r"""
    One iteration of the CIPSI method. 

    For a given Slater determinant :math:`|a\rangle` accessible from a given wavefunction :math:`|\psi\rangle`, 
    the estimated coefficient at 2nd order Nesbet perturbation theory is
    .. math::

        c^{PT2}_a = \frac{|\langle a | H | \psi \rangle|^2}
                         {\langle \psi | H | \psi \rangle - \langle a | H | a \rangle}

    Args : 
        hwf: :math:`H|\psi\rangle`, a Wavefunction object 
        ewf: the energy :math:`\langle \psi|H|\psi\rangle`, a scalar
        one_body_terms: the one_body part of the hamiltonian 
        two_body_terms: ..
        K : the number of spin-orbitals 
        h0: the one particle hamiltonian 
        U : the two particle hamitlonian 
        thr : Basis elements with absolute coefficient below threshold are pruned before expansion

    Returns:
        diffbasis_sorted : the new basis elements sorted according to their PT2 coefficients

    """
    c_PT2 = np.zeros(len(diffbasis))

    for i,d in enumerate(diffbasis):
        occ_i = d.get_occupied_spin_orbitals()
        ahwf = hwf.amplitude(d)
        aha = cc.KL(occ_i, occ_i, K, h0, U)

        c_PT2[i] = np.abs(ahwf)**2 / np.real(ewf - aha + 1e-8)

    indsort = np.argsort(np.abs(c_PT2))[::-1]
    diffbasis_sorted = [diffbasis[i] for i in indsort]

    return diffbasis_sorted




import numpy as np
from typing import Tuple, Literal

def _probs(c: np.ndarray) -> np.ndarray:
    """
    Return normalized probabilities p_i = |c_i|^2 / sum_j |c_j|^2.
    Handles complex c and the all-zero edge case.
    """
    c = np.asarray(c)
    w = np.abs(c)**2
    Z = w.sum()
    if Z == 0:
        # convention: uniform if the vector is identically zero
        return np.ones_like(w, dtype=float) / max(1, w.size)
    return w / Z

def ipr(c: np.ndarray) -> float:
    """
    Inverse Participation Ratio: sum_i p_i^2, where p_i = |c_i|^2 / sum |c|^2.
    Larger IPR => more concentrated.
    """
    p = _probs(c)
    return float(np.sum(p**2))

def pr(c: np.ndarray) -> float:
    """
    Participation number: 1 / IPR. Interpreted as the 'effective' number of components.
    """
    I = ipr(c)
    return float(1.0 / I) if I > 0 else np.inf

def ipr_sparsity_score(c: np.ndarray) -> float:
    """
    Normalized IPR sparsity score in [0,1]:
        S_IPR = (IPR - 1/n) / (1 - 1/n)
    Returns 1 for a basis vector, 0 for the uniform vector.
    """
    n = max(1, int(np.size(c)))
    if n == 1:
        return 1.0
    I = ipr(c)
    return float((I - 1.0/n) / (1.0 - 1.0/n))

def shannon_entropy(c: np.ndarray, base: float = np.e) -> float:
    """
    Shannon entropy H = -sum p_i log p_i (with log in the given base).
    Zeros are handled with the usual 0*log0 -> 0 convention.
    """
    p = _probs(c)
    # mask zeros to avoid log issues
    mask = p > 0
    logp = np.log(p[mask])
    if base != np.e:
        logp = logp / np.log(base)
    H = -float(np.dot(p[mask], logp))
    return H

def shannon_sparsity_score(c: np.ndarray, base: float = np.e) -> float:
    """
    Normalized Shannon sparsity score in [0,1]:
        S_Sh = 1 - H / log_base(n)
    Returns 1 for a basis vector, 0 for the uniform vector.
    """
    n = max(1, int(np.size(c)))
    if n == 1:
        return 1.0
    H = shannon_entropy(c, base=base)
    logn = np.log(n) / (np.log(base) if base != np.e else 1.0)
    return float(1.0 - H / logn)

def top_k_coverage(c: np.ndarray, alpha: float = 0.9) -> Tuple[int, float]:
    """
    Smallest K such that sum of the K largest p_i >= alpha.
    Returns (K, K/n). If alpha <= 0, returns (0, 0.0). If alpha > 1, clamps to 1.
    """
    p = _probs(c)
    n = int(p.size)
    if n == 0:
        return 0, 0.0
    a = float(np.clip(alpha, 0.0, 1.0))
    if a <= 0:
        return 0, 0.0
    ps = np.sort(p)[::-1]
    cs = np.cumsum(ps)
    K = int(np.searchsorted(cs, a, side="left") + 1)
    K = min(K, n)
    return K, K / n

def epsilon_support_size(
    c: np.ndarray,
    epsilon: float,
    mode: Literal["amplitude", "prob"] = "amplitude"
) -> int:
    """
    Count of indices above a threshold:
      - mode="amplitude": |c_i| >= epsilon     (threshold on amplitudes)
      - mode="prob":      p_i   >= epsilon     (threshold on probabilities)
    """
    if mode == "amplitude":
        return int(np.count_nonzero(np.abs(c) >= epsilon))
    elif mode == "prob":
        p = _probs(c)
        return int(np.count_nonzero(p >= epsilon))
    else:
        raise ValueError("mode must be 'amplitude' or 'prob'")

import numpy as np
from scipy.sparse import csr_matrix
from scipy.sparse.csgraph import connected_components
from typing import List, Dict

def get_block_structure(h0: np.ndarray, tol: float = 1e-6) -> List[List[int]]:
    """
    Finds the block-diagonal structure of a Hamiltonian.

    This function treats the orbitals as nodes in a graph where an edge exists
    if the corresponding off-diagonal element in the Hamiltonian `h0` is
    non-zero (larger than `tol`). It then finds the connected components
    of this graph, which correspond to the decoupled blocks of the Hamiltonian.

    Args:
        h0 (np.ndarray): The one-body Hamiltonian matrix (M x M or 2M x 2M).
        tol (float): The tolerance for considering an off-diagonal element
                     to be non-zero.

    Returns:
        List[List[int]]: A list of blocks, where each block is a list of
                         the orbital indices that belong to it.
    """
    if h0.ndim != 2 or h0.shape[0] != h0.shape[1]:
        raise ValueError("h0 must be a square 2D array.")

    n_orb = h0.shape[0]
    
    # Create a boolean adjacency matrix: True where orbitals are coupled
    mask = np.abs(h0) > tol
    
    # The diagonal doesn't determine connections between different nodes
    np.fill_diagonal(mask, False)

    # Use scipy's graph tools to find connected components
    graph = csr_matrix(mask)
    n_components, labels = connected_components(graph, directed=False, connection='weak')

    # Group indices by their component label
    blocks = [[] for _ in range(n_components)]
    for i, label in enumerate(labels):
        blocks[label].append(i)
        
    return [sorted(block) for block in blocks]


def get_identical_blocks(blocks: List[List[int]], h0: np.ndarray, tol: float = 1e-6) -> List[List[int]]:
    """
    Finds groups of identical blocks within a block-diagonal Hamiltonian.

    For identifying symmetries, such as spin degeneracy if the
    spin-up and spin-down blocks are identical.

    Args:
        blocks (List[List[int]]): The block structure, as returned by
                                  `get_block_structure`.
        h0 (np.ndarray): The full one-body Hamiltonian matrix.
        tol (float): The tolerance for comparing submatrices of the blocks.

    Returns:
        List[List[int]]: A list of groups. Each group is a list of the
                         original indices (from the `blocks` list) of the
                         blocks that were found to be identical.
    """
    num_blocks = len(blocks)
    identical_groups = []
    visited_block_indices = set()

    for i in range(num_blocks):
        if i in visited_block_indices:
            continue

        current_group = [i]
        block_i = blocks[i]
        h_i = h0[np.ix_(block_i, block_i)]

        for j in range(i + 1, num_blocks):
            if j in visited_block_indices:
                continue
            
            block_j = blocks[j]

            # A necessary condition for being identical is having the same size
            if len(block_i) != len(block_j):
                continue
            
            h_j = h0[np.ix_(block_j, block_j)]

            # Compare the submatrices within the specified tolerance
            if np.allclose(h_i, h_j, atol=tol):
                current_group.append(j)
                visited_block_indices.add(j)
        
        identical_groups.append(current_group)
        visited_block_indices.add(i)
        
    return identical_groups


def is_diagonal(blocks: List[List[int]]) -> bool:
    """
    Checks if the Hamiltonian is purely diagonal based on its block structure.

    Args:
        blocks (List[List[int]]): The block structure from `get_block_structure`.

    Returns:
        bool: True if every block contains only a single orbital, False otherwise.
    """
    return all(len(block) == 1 for block in blocks)


def analyze_symmetries(h0: np.ndarray, tol: float = 1e-6, verbose=False) -> Dict:
    """
    A convenient wrapper function to perform a full symmetry analysis.

    Args:
        h0 (np.ndarray): The one-body Hamiltonian matrix.
        tol (float): The tolerance for all comparisons.

    Returns:
        Dict: A dictionary containing the analysis results:
              - 'blocks': The decoupled blocks of indices.
              - 'identical_groups': Groups of indices of identical blocks.
              - 'is_diagonal': A boolean indicating if h0 is diagonal.
    """
    blocks = get_block_structure(h0, tol)
    identical = get_identical_blocks(blocks, h0, tol)
    diag = is_diagonal(blocks)

    if verbose:
        print("\n--- Analyzed Structure ---")
        print(f"Blocks: {blocks}")
        print(f"Identical Groups (by block index): {identical}")
    
    return {
        "blocks": blocks,
        "identical_groups": identical,
        "is_diagonal": diag
    }


# ---------------------------------------------------------

def reconstruct_matrix_from_blocks(
    blocks: List[List[int]], 
    block_matrices: List[np.ndarray],
    dtype=np.complex128
) -> np.ndarray:
    """
    Reconstructs a full matrix from its block-diagonal components.

    This is the inverse operation of `get_block_structure`. It places each
    matrix from `block_matrices` onto the diagonal of a larger zero matrix
    at the locations specified by `blocks`.

    Args:
        blocks (List[List[int]]): The block structure, where each inner list
                                  contains the indices for that block.
        block_matrices (List[np.ndarray]): A list of square matrices, where
                                          `block_matrices[i]` corresponds
                                          to the block defined by `blocks[i]`.
        dtype: The numpy data type for the output matrix.

    Returns:
        np.ndarray: The assembled full matrix.
        
    Example:
        >>> blocks = [[0, 2], [1]]
        >>> block_mats = [np.array([[1,1],[1,1]]), np.array([[5]])]
        >>> reconstruct_matrix_from_blocks(blocks, block_mats)
        array([[1., 0., 1.],
               [0., 5., 0.],
               [1., 0., 1.]])
    """
    if len(blocks) != len(block_matrices):
        raise ValueError(
            f"Mismatch: {len(blocks)} blocks were provided, but "
            f"{len(block_matrices)} block matrices were given."
        )

    # Determine the size of the final matrix
    if not blocks:
        return np.array([[]], dtype=dtype)
    
    # Check for overlapping indices and validate matrix sizes
    all_indices = []
    for i, b_indices in enumerate(blocks):
        mat = block_matrices[i]
        if mat.shape != (len(b_indices), len(b_indices)):
            raise ValueError(
                f"Shape mismatch for block {i}: block indices have size "
                f"{len(b_indices)}, but provided matrix has shape {mat.shape}."
            )
        all_indices.extend(b_indices)
    
    if len(set(all_indices)) != len(all_indices):
        raise ValueError("Overlapping indices detected in the block structure.")

    max_index = max(all_indices) if all_indices else -1
    full_size = max_index + 1

    # Create the full matrix and fill it
    full_matrix = np.zeros((full_size, full_size), dtype=dtype)
    
    for block_indices, matrix in zip(blocks, block_matrices):
        # Use np.ix_ for elegant and efficient submatrix assignment
        full_matrix[np.ix_(block_indices, block_indices)] = matrix
        
    return full_matrix


def assemble_symmetric_hamiltonian(
    sym_dict,
    unique_matrices: Dict[int, np.ndarray],
    dtype=np.complex128
) -> np.ndarray:
    """
    A high-level wrapper to reconstruct a Hamiltonian using symmetry information.

    This function simplifies the creation of a full Hamiltonian when you know
    which blocks are identical and only need to define the matrix for one
    member of each identical group.

    Args:
        sym_dict : Dictionnary holding the block structure
        unique_matrices (Dict[int, np.ndarray]): A dictionary mapping the first index
                                                 of an identical group to its
                                                 corresponding matrix.
        dtype: The numpy data type for the output matrix.

    Returns:
        np.ndarray: The assembled full symmetric Hamiltonian.
    """

 
    blocks = sym_dict["blocks"]
    identical_groups = sym_dict["identical_groups"]

    num_blocks = len(blocks)
    full_block_matrices = [None] * num_blocks

    for group in identical_groups:
        leader_idx = group[0]
        if leader_idx not in unique_matrices:
            raise KeyError(f"Matrix for representative block index {leader_idx} was not provided.")
        
        matrix_for_group = unique_matrices[leader_idx]
        
        for member_idx in group:
            full_block_matrices[member_idx] = matrix_for_group
            
    if any(m is None for m in full_block_matrices):
        raise ValueError("Some blocks were not assigned a matrix. Check `identical_groups`.")

    return reconstruct_matrix_from_blocks(blocks, full_block_matrices, dtype=dtype)